{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c8e3386",
   "metadata": {},
   "source": [
    "# 🎯 Day 4.6 - Mask-Guided Attention Training (90%+ Target)\n",
    "\n",
    "## 🎯 Learning Objectives\n",
    "\n",
    "In this notebook, you'll:\n",
    "1. **Use tumor masks** to create attention-weighted training\n",
    "2. **Focus model on tumor regions** rather than skull/background\n",
    "3. **Implement mask-based data augmentation**\n",
    "4. **Train with region-of-interest (ROI) focus**\n",
    "5. **Achieve 90%+ accuracy** by leveraging segmentation masks\n",
    "\n",
    "---\n",
    "\n",
    "## 💡 **Why Masks Matter:**\n",
    "\n",
    "Current problem: Model is confused because it looks at **entire brain** including:\n",
    "- ❌ Skull boundaries\n",
    "- ❌ Background noise\n",
    "- ❌ Non-tumor tissue\n",
    "\n",
    "**With masks, we can:**\n",
    "- ✅ Focus on **tumor regions only**\n",
    "- ✅ Apply stronger augmentation to tumor area\n",
    "- ✅ Weight loss by tumor importance\n",
    "- ✅ Extract tumor-specific features\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d69bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 🔧 Setup\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, Flatten, Dense, \n",
    "    Dropout, Multiply, Lambda, Concatenate\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, '../..')\n",
    "from src.modeling.model_cnn import enable_gpu_memory_growth\n",
    "\n",
    "# Setup\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(f\"GPU: {tf.config.list_physical_devices('GPU')}\")\n",
    "enable_gpu_memory_growth()\n",
    "\n",
    "sns.set_style('white')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"\\n✅ Libraries imported successfully\")\n",
    "print(f\"⏰ Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e39214",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 📂 Paths Configuration\n",
    "\n",
    "# Data paths\n",
    "TRAIN_CSV = '../../outputs/data_splits/train_split.csv'\n",
    "VAL_CSV = '../../outputs/data_splits/val_split.csv'\n",
    "TEST_CSV = '../../outputs/data_splits/test_split.csv'\n",
    "\n",
    "# Image directories\n",
    "IMAGES_DIR = '../../outputs/ce_mri_enhanced'\n",
    "MASKS_DIR = '../../outputs/ce_mri_masks'\n",
    "\n",
    "# Output directories\n",
    "MODELS_DIR = '../../outputs/models'\n",
    "LOGS_DIR = '../../outputs/logs'\n",
    "VIZ_DIR = '../../outputs/visualizations'\n",
    "METRICS_DIR = '../../outputs/metrics'\n",
    "\n",
    "for directory in [MODELS_DIR, LOGS_DIR, VIZ_DIR, METRICS_DIR]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "print(\"✅ Paths configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f98d2d4",
   "metadata": {},
   "source": [
    "## 🎨 Custom Data Generator with Masks\n",
    "\n",
    "This generator will:\n",
    "1. Load image AND corresponding mask\n",
    "2. Apply same augmentation to both\n",
    "3. Multiply image by mask to focus on tumor\n",
    "4. Return (masked_image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb34c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskGuidedDataGenerator(tf.keras.utils.Sequence):\n",
    "    \"\"\"Data generator that uses tumor masks for attention-focused training.\"\"\"\n",
    "    \n",
    "    def __init__(self, csv_path, batch_size=32, target_size=(128, 128),\n",
    "                 images_dir='../../outputs/ce_mri_enhanced',\n",
    "                 masks_dir='../../outputs/ce_mri_masks',\n",
    "                 augment=True, shuffle=True):\n",
    "        \n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.images_dir = images_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        self.augment = augment\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.df))\n",
    "        \n",
    "        # Augmentation parameters\n",
    "        self.rotation_range = 15\n",
    "        self.width_shift_range = 0.1\n",
    "        self.height_shift_range = 0.1\n",
    "        self.zoom_range = 0.1\n",
    "        self.horizontal_flip = True\n",
    "        \n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_data = self.df.iloc[batch_indices]\n",
    "        \n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        for _, row in batch_data.iterrows():\n",
    "            # Load image\n",
    "            img_path = row['filepath']\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, self.target_size)\n",
    "            img = img.astype('float32') / 255.0\n",
    "            \n",
    "            # Load corresponding mask\n",
    "            mask_path = img_path.replace(self.images_dir, self.masks_dir)\n",
    "            if os.path.exists(mask_path):\n",
    "                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "                mask = cv2.resize(mask, self.target_size)\n",
    "                mask = (mask > 127).astype('float32')  # Binarize\n",
    "                \n",
    "                # Dilate mask slightly to include tumor boundary\n",
    "                kernel = np.ones((3, 3), np.uint8)\n",
    "                mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "            else:\n",
    "                mask = np.ones(self.target_size, dtype='float32')\n",
    "            \n",
    "            # Apply augmentation if enabled\n",
    "            if self.augment:\n",
    "                img, mask = self._augment(img, mask)\n",
    "            \n",
    "            # Apply mask attention: focus on tumor region\n",
    "            # Keep some background context (0.3 weight)\n",
    "            attended_img = img * (0.3 + 0.7 * mask)\n",
    "            \n",
    "            # Add channel dimension\n",
    "            attended_img = np.expand_dims(attended_img, axis=-1)\n",
    "            \n",
    "            images.append(attended_img)\n",
    "            \n",
    "            # Label (0-indexed for model)\n",
    "            label = row['label'] - 1\n",
    "            labels.append(label)\n",
    "        \n",
    "        # Convert to arrays\n",
    "        X = np.array(images)\n",
    "        y = tf.keras.utils.to_categorical(labels, num_classes=3)\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def _augment(self, img, mask):\n",
    "        \"\"\"Apply same augmentation to image and mask.\"\"\"\n",
    "        if np.random.rand() < 0.5:\n",
    "            # Rotation\n",
    "            angle = np.random.uniform(-self.rotation_range, self.rotation_range)\n",
    "            center = (img.shape[1] // 2, img.shape[0] // 2)\n",
    "            M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "            img = cv2.warpAffine(img, M, img.shape[::-1])\n",
    "            mask = cv2.warpAffine(mask, M, mask.shape[::-1])\n",
    "        \n",
    "        if np.random.rand() < 0.5:\n",
    "            # Horizontal flip\n",
    "            img = cv2.flip(img, 1)\n",
    "            mask = cv2.flip(mask, 1)\n",
    "        \n",
    "        if np.random.rand() < 0.5:\n",
    "            # Translation\n",
    "            tx = np.random.uniform(-self.width_shift_range, self.width_shift_range) * img.shape[1]\n",
    "            ty = np.random.uniform(-self.height_shift_range, self.height_shift_range) * img.shape[0]\n",
    "            M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "            img = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))\n",
    "            mask = cv2.warpAffine(mask, M, (mask.shape[1], mask.shape[0]))\n",
    "        \n",
    "        return img, mask\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "print(\"✅ MaskGuidedDataGenerator class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdc56a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 📊 Create Data Generators\n",
    "\n",
    "print(\"📂 Creating mask-guided data generators...\\n\")\n",
    "\n",
    "# Training generator (with augmentation and mask attention)\n",
    "train_gen = MaskGuidedDataGenerator(\n",
    "    csv_path=TRAIN_CSV,\n",
    "    batch_size=32,\n",
    "    target_size=(128, 128),\n",
    "    images_dir=IMAGES_DIR,\n",
    "    masks_dir=MASKS_DIR,\n",
    "    augment=True,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Validation generator (no augmentation, but with mask attention)\n",
    "val_gen = MaskGuidedDataGenerator(\n",
    "    csv_path=VAL_CSV,\n",
    "    batch_size=32,\n",
    "    target_size=(128, 128),\n",
    "    images_dir=IMAGES_DIR,\n",
    "    masks_dir=MASKS_DIR,\n",
    "    augment=False,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"✅ Training generator: {len(train_gen)} batches\")\n",
    "print(f\"✅ Validation generator: {len(val_gen)} batches\")\n",
    "\n",
    "# Visualize sample\n",
    "print(\"\\n📊 Sample batch:\")\n",
    "X_sample, y_sample = train_gen[0]\n",
    "print(f\"   Input shape: {X_sample.shape}\")\n",
    "print(f\"   Label shape: {y_sample.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7278e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 🖼️ Visualize Mask-Attended Images\n",
    "\n",
    "# Show examples of mask-attended images\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for i in range(8):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    \n",
    "    img = X_sample[i, :, :, 0]\n",
    "    label = np.argmax(y_sample[i])\n",
    "    label_name = ['Meningioma', 'Glioma', 'Pituitary'][label]\n",
    "    \n",
    "    axes[row, col].imshow(img, cmap='gray')\n",
    "    axes[row, col].set_title(f'{label_name}', fontweight='bold')\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.suptitle('🎯 Mask-Attended Training Images (Tumor-Focused)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "viz_path = os.path.join(VIZ_DIR, 'day4_06_mask_attended_samples.png')\n",
    "plt.savefig(viz_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"✅ Visualization saved: {viz_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f82b8d2",
   "metadata": {},
   "source": [
    "## 🏗️ Build Enhanced CNN Model\n",
    "\n",
    "Larger capacity model for better feature extraction from tumor regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffb9cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Calculate class weights\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_df['label']),\n",
    "    y=train_df['label']\n",
    ")\n",
    "class_weights = {i: weight for i, weight in enumerate(class_weights_array)}\n",
    "\n",
    "print(\"⚖️ Class Weights:\")\n",
    "for class_idx, weight in class_weights.items():\n",
    "    tumor_type = {0: 'Meningioma', 1: 'Glioma', 2: 'Pituitary'}[class_idx]\n",
    "    print(f\"   Class {class_idx} ({tumor_type}): {weight:.4f}x\")\n",
    "\n",
    "# Build model\n",
    "def build_mask_aware_cnn(input_shape=(128, 128, 1), num_classes=3, learning_rate=5e-5):\n",
    "    \"\"\"\n",
    "    Enhanced CNN with more capacity for mask-attended features.\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        # Block 1\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Block 2\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Block 3\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Dense layers\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ], name='MaskAwareCNN')\n",
    "    \n",
    "    # Compile with lower learning rate\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_mask_aware_cnn(\n",
    "    input_shape=(128, 128, 1),\n",
    "    num_classes=3,\n",
    "    learning_rate=5e-5\n",
    ")\n",
    "\n",
    "print(f\"\\n📊 Model Architecture:\")\n",
    "model.summary()\n",
    "\n",
    "total_params = model.count_params()\n",
    "print(f\"\\n✅ Total parameters: {total_params:,}\")\n",
    "print(f\"   Model size: ~{total_params * 4 / 1024 / 1024:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80bd2d3",
   "metadata": {},
   "source": [
    "## 🎛️ Setup Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82771a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, \n",
    "    CSVLogger, Callback\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpoint_path = os.path.join(MODELS_DIR, 'model_mask_aware_best.h5')\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "csv_log_path = os.path.join(LOGS_DIR, 'training_log_mask_aware.csv')\n",
    "csv_logger = CSVLogger(csv_log_path)\n",
    "\n",
    "# LR Tracker\n",
    "class LRTracker(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lrs = []\n",
    "        self.epochs = []\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        self.lrs.append(lr)\n",
    "        self.epochs.append(epoch + 1)\n",
    "        logs['lr'] = lr\n",
    "\n",
    "lr_tracker = LRTracker()\n",
    "\n",
    "callbacks_list = [early_stopping, model_checkpoint, reduce_lr, csv_logger, lr_tracker]\n",
    "\n",
    "print(\"✅ Callbacks configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78910fdc",
   "metadata": {},
   "source": [
    "## 🚀 Train Mask-Aware Model\n",
    "\n",
    "**Target: 90%+ test accuracy**\n",
    "\n",
    "Training with:\n",
    "- ✅ Mask-guided attention\n",
    "- ✅ Class weights for balance\n",
    "- ✅ Enhanced model capacity\n",
    "- ✅ Lower learning rate (5e-5)\n",
    "- ✅ More epochs (25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0df357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "EPOCHS = 25\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"🏋️ STARTING MASK-AWARE TRAINING\")\n",
    "print(\"=\"*70)\n",
    "print(f\"⏰ Start time: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "print(f\"📊 Max epochs: {EPOCHS}\")\n",
    "print(f\"🎯 Target: 90%+ test accuracy\")\n",
    "print(f\"⚖️ Using balanced class weights\")\n",
    "print(f\"🎭 Using tumor mask attention\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks_list,\n",
    "    class_weight=class_weights,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "minutes = int(training_time // 60)\n",
    "seconds = int(training_time % 60)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✅ TRAINING COMPLETED\")\n",
    "print(\"=\"*70)\n",
    "print(f\"⏰ End time: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "print(f\"⌛ Total time: {minutes}m {seconds}s\")\n",
    "print(f\"📈 Epochs completed: {len(history.history['loss'])}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c15d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 📊 Training Curves\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs_completed = len(train_loss)\n",
    "epochs_range = range(1, epochs_completed + 1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(epochs_range, train_acc, 'b-o', label='Training', linewidth=2)\n",
    "axes[0].plot(epochs_range, val_acc, 'r-s', label='Validation', linewidth=2)\n",
    "axes[0].axhline(y=max(val_acc), color='g', linestyle='--', alpha=0.5)\n",
    "axes[0].set_title(f'Model Accuracy (Best Val: {max(val_acc)*100:.2f}%)', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(epochs_range, train_loss, 'b-o', label='Training', linewidth=2)\n",
    "axes[1].plot(epochs_range, val_loss, 'r-s', label='Validation', linewidth=2)\n",
    "axes[1].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "curves_path = os.path.join(VIZ_DIR, 'day4_06_mask_aware_training_curves.png')\n",
    "plt.savefig(curves_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"✅ Training curves saved: {curves_path}\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n📊 Training Summary:\")\n",
    "print(f\"   Best validation accuracy: {max(val_acc)*100:.2f}%\")\n",
    "print(f\"   Final training accuracy: {train_acc[-1]*100:.2f}%\")\n",
    "print(f\"   Overfitting gap: {(train_acc[-1] - val_acc[-1])*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e831fa85",
   "metadata": {},
   "source": [
    "## 🧪 Evaluate on Test Set\n",
    "\n",
    "Let's see if we hit our 90%+ target!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66da6b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Create test generator\n",
    "test_gen = MaskGuidedDataGenerator(\n",
    "    csv_path=TEST_CSV,\n",
    "    batch_size=32,\n",
    "    target_size=(128, 128),\n",
    "    images_dir=IMAGES_DIR,\n",
    "    masks_dir=MASKS_DIR,\n",
    "    augment=False,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"🔮 Generating predictions on test set...\\n\")\n",
    "\n",
    "# Predict\n",
    "y_pred_probs = model.predict(test_gen, verbose=1)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# True labels\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "y_true = (test_df['label'] - 1).values\n",
    "\n",
    "# Calculate accuracy\n",
    "test_accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"🎯 TEST SET PERFORMANCE (MASK-AWARE MODEL)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n📊 Overall Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"   Correct: {np.sum(y_true == y_pred)} / {len(y_true)}\")\n",
    "print(f\"   Incorrect: {np.sum(y_true != y_pred)} / {len(y_true)}\")\n",
    "\n",
    "if test_accuracy >= 0.90:\n",
    "    print(f\"\\n🎉 ✅ TARGET ACHIEVED! {test_accuracy*100:.2f}% >= 90%\")\n",
    "else:\n",
    "    print(f\"\\n⚠️ Target not yet reached ({test_accuracy*100:.2f}% < 90%)\")\n",
    "    print(\"   Consider: longer training, more augmentation, or ensemble methods\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Classification report\n",
    "class_names = ['Meningioma', 'Glioma', 'Pituitary']\n",
    "print(\"\\n📋 CLASSIFICATION REPORT\")\n",
    "print(\"=\"*70)\n",
    "y_true_labels = y_true + 1\n",
    "y_pred_labels = y_pred + 1\n",
    "report = classification_report(y_true_labels, y_pred_labels, target_names=class_names, digits=4)\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true_labels, y_pred_labels, labels=[1, 2, 3])\n",
    "print(\"\\n🔲 CONFUSION MATRIX\")\n",
    "print(\"=\"*70)\n",
    "print(cm)\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df38742",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 📈 Visualize Confusion Matrix\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Raw counts\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            ax=axes[0], cbar_kws={'label': 'Count'})\n",
    "axes[0].set_title('Confusion Matrix (Counts)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Actual Class')\n",
    "axes[0].set_xlabel('Predicted Class')\n",
    "\n",
    "# Normalized\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_norm, annot=True, fmt='.2%', cmap='RdYlGn',\n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            ax=axes[1], cbar_kws={'label': 'Percentage'}, vmin=0, vmax=1)\n",
    "axes[1].set_title('Confusion Matrix (Normalized)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Actual Class')\n",
    "axes[1].set_xlabel('Predicted Class')\n",
    "\n",
    "plt.tight_layout()\n",
    "cm_path = os.path.join(VIZ_DIR, 'day4_06_mask_aware_confusion_matrix.png')\n",
    "plt.savefig(cm_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"✅ Confusion matrix saved: {cm_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d932aa1f",
   "metadata": {},
   "source": [
    "## ✅ Summary\n",
    "\n",
    "### What We Accomplished:\n",
    "\n",
    "1. ✅ **Mask-guided attention** - Model focuses on tumor regions\n",
    "2. ✅ **Enhanced architecture** - Deeper network with more capacity\n",
    "3. ✅ **Class weighting** - Balanced training across classes\n",
    "4. ✅ **Improved augmentation** - Masks help preserve tumor structure\n",
    "\n",
    "### Results:\n",
    "\n",
    "**Test Accuracy:** {test_accuracy*100:.2f}%\n",
    "\n",
    "**Improvements over baseline (71.76%):**\n",
    "- Absolute gain: {(test_accuracy - 0.7176)*100:.2f} percentage points\n",
    "- Relative improvement: {((test_accuracy / 0.7176) - 1)*100:.1f}%\n",
    "\n",
    "### If Target Not Reached (< 90%):\n",
    "\n",
    "**Additional strategies:**\n",
    "1. **Ensemble methods** - Combine multiple models\n",
    "2. **Transfer learning** - Use pre-trained models (ResNet, EfficientNet)\n",
    "3. **Longer training** - 40-50 epochs with careful monitoring\n",
    "4. **External data** - Augment with similar datasets\n",
    "5. **Test-time augmentation** - Average predictions over multiple augmentations\n",
    "\n",
    "---\n",
    "\n",
    "**Date:** October 22, 2025  \n",
    "**Status:** ✅ Completed  \n",
    "**Best Model:** `model_mask_aware_best.h5`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
