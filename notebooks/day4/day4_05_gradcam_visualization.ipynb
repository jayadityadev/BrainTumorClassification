{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2674fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "````xml\n",
    "<VSCode.Cell language=\"markdown\">\n",
    "# üîç Day 4.5 - Grad-CAM Visualization (Model Interpretability)\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "In this notebook, you'll:\n",
    "1. **Understand Grad-CAM** - Gradient-weighted Class Activation Mapping\n",
    "2. **Visualize what the CNN focuses on** when making predictions\n",
    "3. **Generate heatmaps** overlaid on MRI images\n",
    "4. **Interpret model decisions** for each tumor type\n",
    "5. **Enhance explainability** for medical AI applications\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Theory: Grad-CAM\n",
    "\n",
    "### What Is Grad-CAM?\n",
    "\n",
    "**Grad-CAM** = **Grad**ient-weighted **C**lass **A**ctivation **M**apping\n",
    "\n",
    "It visualizes which regions of an image the CNN focuses on for a specific prediction.\n",
    "\n",
    "### How It Works:\n",
    "\n",
    "1. **Forward pass**: Get prediction for an image\n",
    "2. **Backward pass**: Calculate gradients of target class w.r.t. last conv layer\n",
    "3. **Weight feature maps**: By average gradients\n",
    "4. **Create heatmap**: Weighted combination of feature maps\n",
    "5. **Overlay on image**: Show where model \"looks\"\n",
    "\n",
    "### Why It Matters for Medical AI:\n",
    "\n",
    "| Aspect | Importance |\n",
    "|--------|------------|\n",
    "| **Trust** | Doctors need to see *why* the model predicts something |\n",
    "| **Validation** | Verify model focuses on tumor, not artifacts |\n",
    "| **Error Analysis** | Understand why misclassifications happen |\n",
    "| **Regulatory** | FDA/CE marking requires explainability |\n",
    "\n",
    "---\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"markdown\">\n",
    "## üîß Setup\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "# Check TensorFlow\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# Set style\n",
    "sns.set_style('white')\n",
    "plt.rcParams['figure.figsize'] = (16, 10)\n",
    "\n",
    "print(\"\\n‚úÖ Libraries imported successfully\")\n",
    "print(f\"‚è∞ Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"markdown\">\n",
    "## üìÇ Define Paths\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "# Model path\n",
    "MODEL_PATH = '../../outputs/models/model_cnn_best.h5'\n",
    "\n",
    "# Data paths\n",
    "TEST_CSV = '../../outputs/data_splits/test_split.csv'\n",
    "\n",
    "# Output path\n",
    "VIZ_DIR = '../../outputs/visualizations'\n",
    "os.makedirs(VIZ_DIR, exist_ok=True)\n",
    "\n",
    "# Class names\n",
    "CLASS_NAMES = {0: 'Meningioma', 1: 'Glioma', 2: 'Pituitary'}\n",
    "\n",
    "print(\"‚úÖ Paths configured\")\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"markdown\">\n",
    "## üíæ Load Model\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "print(f\"üì• Loading model from: {MODEL_PATH}\\n\")\n",
    "\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    model = load_model(MODEL_PATH)\n",
    "    print(\"‚úÖ Model loaded successfully\")\n",
    "    \n",
    "    # Print layer names to find last conv layer\n",
    "    print(\"\\nüìä Model Layers:\")\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        print(f\"   {i}: {layer.name} ({type(layer).__name__})\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Model not found: {MODEL_PATH}\")\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"markdown\">\n",
    "## üéØ Identify Last Convolutional Layer\n",
    "\n",
    "For Grad-CAM, we need the last convolutional layer (before Flatten).\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "# Find last convolutional layer\n",
    "last_conv_layer_name = None\n",
    "for layer in reversed(model.layers):\n",
    "    if 'conv' in layer.name.lower():\n",
    "        last_conv_layer_name = layer.name\n",
    "        break\n",
    "\n",
    "print(f\"üîç Last convolutional layer: {last_conv_layer_name}\")\n",
    "\n",
    "# Verify it exists\n",
    "last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "print(f\"   Output shape: {last_conv_layer.output_shape}\")\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"markdown\">\n",
    "## üé® Grad-CAM Implementation\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    \"\"\"\n",
    "    Generate Grad-CAM heatmap for a given image.\n",
    "    \n",
    "    Args:\n",
    "        img_array: Input image array (1, H, W, C)\n",
    "        model: Keras model\n",
    "        last_conv_layer_name: Name of last conv layer\n",
    "        pred_index: Class index to visualize (None = predicted class)\n",
    "        \n",
    "    Returns:\n",
    "        heatmap: Grad-CAM heatmap (H, W)\n",
    "    \"\"\"\n",
    "    # Create a model that maps input to activations of last conv layer and output predictions\n",
    "    grad_model = Model(\n",
    "        inputs=model.input,\n",
    "        outputs=[model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "    \n",
    "    # Compute gradient of predicted class w.r.t. feature maps\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(predictions[0])\n",
    "        class_channel = predictions[:, pred_index]\n",
    "    \n",
    "    # Gradients of the output neuron w.r.t. output feature map\n",
    "    grads = tape.gradient(class_channel, conv_outputs)\n",
    "    \n",
    "    # Average gradients spatially (global average pooling)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    \n",
    "    # Weight feature maps by gradients\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    \n",
    "    # Normalize heatmap to [0, 1]\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    \n",
    "    return heatmap.numpy()\n",
    "\n",
    "\n",
    "def overlay_heatmap_on_image(img, heatmap, alpha=0.4, colormap=cv2.COLORMAP_JET):\n",
    "    \"\"\"\n",
    "    Overlay Grad-CAM heatmap on original image.\n",
    "    \n",
    "    Args:\n",
    "        img: Original image (H, W) or (H, W, 3)\n",
    "        heatmap: Grad-CAM heatmap (H, W)\n",
    "        alpha: Transparency of heatmap\n",
    "        colormap: OpenCV colormap\n",
    "        \n",
    "    Returns:\n",
    "        superimposed_img: Image with heatmap overlay\n",
    "    \"\"\"\n",
    "    # Resize heatmap to match image size\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    \n",
    "    # Convert heatmap to RGB\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, colormap)\n",
    "    \n",
    "    # Convert image to RGB if grayscale\n",
    "    if len(img.shape) == 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    elif img.shape[2] == 1:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    # Ensure image is uint8\n",
    "    if img.dtype != np.uint8:\n",
    "        img = np.uint8(255 * img)\n",
    "    \n",
    "    # Superimpose heatmap on image\n",
    "    superimposed_img = cv2.addWeighted(img, 1-alpha, heatmap, alpha, 0)\n",
    "    \n",
    "    return superimposed_img\n",
    "\n",
    "\n",
    "print(\"‚úÖ Grad-CAM functions defined\")\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"markdown\">\n",
    "## üñºÔ∏è Load Sample Images\n",
    "\n",
    "Select representative images from each class.\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "# Load test data\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "\n",
    "# Select 2 samples per class\n",
    "samples_per_class = {}\n",
    "for class_label in [1, 2, 3]:\n",
    "    class_samples = test_df[test_df['label'] == class_label].sample(n=2, random_state=42)\n",
    "    samples_per_class[class_label] = class_samples\n",
    "\n",
    "print(\"üìä Selected samples:\")\n",
    "for class_label, samples in samples_per_class.items():\n",
    "    print(f\"   Class {class_label} ({CLASS_NAMES[class_label-1]}): {len(samples)} samples\")\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"markdown\">\n",
    "## üîç Generate Grad-CAM Visualizations\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "def preprocess_image(img_path, target_size=(128, 128)):\n",
    "    \"\"\"Load and preprocess image for model.\"\"\"\n",
    "    img = image.load_img(img_path, color_mode='grayscale', target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = img_array / 255.0  # Normalize\n",
    "    return img_array, img\n",
    "\n",
    "\n",
    "# Generate Grad-CAM for all samples\n",
    "gradcam_results = []\n",
    "\n",
    "for class_label, samples in samples_per_class.items():\n",
    "    for idx, row in samples.iterrows():\n",
    "        img_path = row['filepath']\n",
    "        true_label = row['label']\n",
    "        \n",
    "        # Load and preprocess\n",
    "        img_array, original_img = preprocess_image(img_path)\n",
    "        \n",
    "        # Get prediction\n",
    "        predictions = model.predict(img_array, verbose=0)\n",
    "        pred_class = np.argmax(predictions[0])\n",
    "        confidence = predictions[0][pred_class] * 100\n",
    "        \n",
    "        # Generate Grad-CAM heatmap\n",
    "        heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=pred_class)\n",
    "        \n",
    "        # Overlay on image\n",
    "        original_img_array = np.array(original_img)\n",
    "        superimposed = overlay_heatmap_on_image(original_img_array, heatmap, alpha=0.5)\n",
    "        \n",
    "        # Store results\n",
    "        gradcam_results.append({\n",
    "            'img_path': img_path,\n",
    "            'original_img': original_img_array,\n",
    "            'heatmap': heatmap,\n",
    "            'superimposed': superimposed,\n",
    "            'true_label': true_label,\n",
    "            'pred_label': pred_class + 1,\n",
    "            'confidence': confidence,\n",
    "            'true_name': CLASS_NAMES[true_label - 1],\n",
    "            'pred_name': CLASS_NAMES[pred_class]\n",
    "        })\n",
    "\n",
    "print(f\"‚úÖ Generated Grad-CAM for {len(gradcam_results)} images\")\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"markdown\">\n",
    "## üìä Visualize Results\n",
    "\n",
    "Display original image, heatmap, and overlay for each sample.\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "# Create comprehensive visualization\n",
    "n_samples = len(gradcam_results)\n",
    "fig, axes = plt.subplots(n_samples, 3, figsize=(14, 4*n_samples))\n",
    "\n",
    "if n_samples == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for i, result in enumerate(gradcam_results):\n",
    "    # Original image\n",
    "    axes[i, 0].imshow(result['original_img'], cmap='gray')\n",
    "    axes[i, 0].axis('off')\n",
    "    axes[i, 0].set_title(\n",
    "        f\"Original\\nTrue: {result['true_name']}\",\n",
    "        fontsize=11, fontweight='bold'\n",
    "    )\n",
    "    \n",
    "    # Heatmap\n",
    "    axes[i, 1].imshow(result['heatmap'], cmap='jet')\n",
    "    axes[i, 1].axis('off')\n",
    "    axes[i, 1].set_title(\n",
    "        f\"Grad-CAM Heatmap\\nPred: {result['pred_name']}\",\n",
    "        fontsize=11, fontweight='bold'\n",
    "    )\n",
    "    \n",
    "    # Overlay\n",
    "    axes[i, 2].imshow(result['superimposed'])\n",
    "    axes[i, 2].axis('off')\n",
    "    \n",
    "    # Color-code title based on correctness\n",
    "    color = 'green' if result['true_label'] == result['pred_label'] else 'red'\n",
    "    axes[i, 2].set_title(\n",
    "        f\"Overlay\\nConfidence: {result['confidence']:.1f}%\",\n",
    "        fontsize=11, fontweight='bold', color=color\n",
    "    )\n",
    "\n",
    "plt.suptitle('Grad-CAM Visualizations: Model Attention Regions', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save\n",
    "gradcam_all_path = os.path.join(VIZ_DIR, 'day4_05_gradcam_all_samples.png')\n",
    "plt.savefig(gradcam_all_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"‚úÖ Grad-CAM visualization saved: {gradcam_all_path}\")\n",
    "plt.show()\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"markdown\">\n",
    "## üéØ Class-Specific Grad-CAM Analysis\n",
    "\n",
    "Show Grad-CAM for each tumor type separately.\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "# Create per-class visualization\n",
    "for class_label in [1, 2, 3]:\n",
    "    class_results = [r for r in gradcam_results if r['true_label'] == class_label]\n",
    "    \n",
    "    if len(class_results) == 0:\n",
    "        continue\n",
    "    \n",
    "    fig, axes = plt.subplots(len(class_results), 3, figsize=(14, 4*len(class_results)))\n",
    "    \n",
    "    if len(class_results) == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i, result in enumerate(class_results):\n",
    "        # Original\n",
    "        axes[i, 0].imshow(result['original_img'], cmap='gray')\n",
    "        axes[i, 0].axis('off')\n",
    "        axes[i, 0].set_title('Original Image', fontsize=11)\n",
    "        \n",
    "        # Heatmap\n",
    "        axes[i, 1].imshow(result['heatmap'], cmap='jet')\n",
    "        axes[i, 1].axis('off')\n",
    "        axes[i, 1].set_title('Attention Heatmap', fontsize=11)\n",
    "        \n",
    "        # Overlay\n",
    "        axes[i, 2].imshow(result['superimposed'])\n",
    "        axes[i, 2].axis('off')\n",
    "        \n",
    "        color = 'green' if result['true_label'] == result['pred_label'] else 'red'\n",
    "        axes[i, 2].set_title(\n",
    "            f\"Pred: {result['pred_name']} ({result['confidence']:.1f}%)\",\n",
    "            fontsize=11, color=color, fontweight='bold'\n",
    "        )\n",
    "    \n",
    "    class_name = CLASS_NAMES[class_label - 1]\n",
    "    plt.suptitle(f'Grad-CAM for {class_name} Tumors', \n",
    "                 fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save\n",
    "    class_path = os.path.join(VIZ_DIR, f'day4_05_gradcam_class_{class_label}_{class_name.lower()}.png')\n",
    "    plt.savefig(class_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"‚úÖ Class {class_label} Grad-CAM saved: {class_path}\")\n",
    "    plt.show()\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"markdown\">\n",
    "## üîç Interpretation Guide\n",
    "\n",
    "### How to Read Grad-CAM Heatmaps:\n",
    "\n",
    "| Color | Meaning |\n",
    "|-------|---------|\n",
    "| **Red/Yellow** | High activation - model focuses here |\n",
    "| **Blue/Purple** | Low activation - model ignores |\n",
    "| **Green** | Medium activation |\n",
    "\n",
    "### What to Look For:\n",
    "\n",
    "1. **Correct Focus**: Is the heatmap centered on the tumor?\n",
    "2. **Artifacts**: Does model focus on image borders or noise?\n",
    "3. **Class Differences**: Do different tumor types activate different regions?\n",
    "\n",
    "### Medical Validation:\n",
    "\n",
    "‚úÖ **Good**: Model focuses on tumor region  \n",
    "‚úÖ **Good**: Attention aligns with radiologist annotations  \n",
    "‚ùå **Bad**: Model focuses on image artifacts  \n",
    "‚ùå **Bad**: Attention on non-tumor regions  \n",
    "\n",
    "---\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"markdown\">\n",
    "## üìä Analysis: Where Does the Model Look?\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "# Analyze attention patterns\n",
    "print(\"üîç Grad-CAM Analysis:\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for class_label in [1, 2, 3]:\n",
    "    class_results = [r for r in gradcam_results if r['true_label'] == class_label]\n",
    "    \n",
    "    if len(class_results) == 0:\n",
    "        continue\n",
    "    \n",
    "    correct = sum(1 for r in class_results if r['true_label'] == r['pred_label'])\n",
    "    accuracy = (correct / len(class_results)) * 100\n",
    "    avg_confidence = np.mean([r['confidence'] for r in class_results])\n",
    "    \n",
    "    # Calculate average heatmap intensity in center vs edges\n",
    "    center_intensities = []\n",
    "    edge_intensities = []\n",
    "    \n",
    "    for r in class_results:\n",
    "        heatmap = r['heatmap']\n",
    "        h, w = heatmap.shape\n",
    "        \n",
    "        # Center region (middle 50%)\n",
    "        center_h_start, center_h_end = h//4, 3*h//4\n",
    "        center_w_start, center_w_end = w//4, 3*w//4\n",
    "        center = heatmap[center_h_start:center_h_end, center_w_start:center_w_end]\n",
    "        center_intensities.append(np.mean(center))\n",
    "        \n",
    "        # Edge region (outer 25%)\n",
    "        edge_thickness = min(h, w) // 8\n",
    "        edge = np.concatenate([\n",
    "            heatmap[:edge_thickness, :].flatten(),\n",
    "            heatmap[-edge_thickness:, :].flatten(),\n",
    "            heatmap[:, :edge_thickness].flatten(),\n",
    "            heatmap[:, -edge_thickness:].flatten()\n",
    "        ])\n",
    "        edge_intensities.append(np.mean(edge))\n",
    "    \n",
    "    avg_center = np.mean(center_intensities)\n",
    "    avg_edge = np.mean(edge_intensities)\n",
    "    center_edge_ratio = avg_center / avg_edge if avg_edge > 0 else 0\n",
    "    \n",
    "    class_name = CLASS_NAMES[class_label - 1]\n",
    "    print(f\"\\n{class_name}:\")\n",
    "    print(f\"   Samples analyzed: {len(class_results)}\")\n",
    "    print(f\"   Prediction accuracy: {accuracy:.1f}%\")\n",
    "    print(f\"   Average confidence: {avg_confidence:.1f}%\")\n",
    "    print(f\"   Avg center activation: {avg_center:.3f}\")\n",
    "    print(f\"   Avg edge activation: {avg_edge:.3f}\")\n",
    "    print(f\"   Center/Edge ratio: {center_edge_ratio:.2f}x\")\n",
    "    \n",
    "    if center_edge_ratio > 2.0:\n",
    "        print(f\"   ‚úÖ Model focuses on center (likely tumor region)\")\n",
    "    elif center_edge_ratio > 1.2:\n",
    "        print(f\"   ‚ö†Ô∏è Model moderately focused on center\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå Model may focus on edges (check for artifacts)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"markdown\">\n",
    "## üí° Interpretation & Insights\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "print(\"\\nüí° KEY INSIGHTS FROM GRAD-CAM ANALYSIS:\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate overall statistics\n",
    "total_correct = sum(1 for r in gradcam_results if r['true_label'] == r['pred_label'])\n",
    "total_samples = len(gradcam_results)\n",
    "overall_accuracy = (total_correct / total_samples) * 100\n",
    "\n",
    "all_center_edge_ratios = []\n",
    "for r in gradcam_results:\n",
    "    heatmap = r['heatmap']\n",
    "    h, w = heatmap.shape\n",
    "    center = heatmap[h//4:3*h//4, w//4:3*w//4]\n",
    "    edge_thickness = min(h, w) // 8\n",
    "    edge = np.concatenate([\n",
    "        heatmap[:edge_thickness, :].flatten(),\n",
    "        heatmap[-edge_thickness:, :].flatten(),\n",
    "        heatmap[:, :edge_thickness].flatten(),\n",
    "        heatmap[:, -edge_thickness:].flatten()\n",
    "    ])\n",
    "    ratio = np.mean(center) / np.mean(edge) if np.mean(edge) > 0 else 0\n",
    "    all_center_edge_ratios.append(ratio)\n",
    "\n",
    "avg_ratio = np.mean(all_center_edge_ratios)\n",
    "\n",
    "print(f\"\\n1Ô∏è‚É£ Model Attention Pattern:\")\n",
    "print(f\"   Average center/edge activation ratio: {avg_ratio:.2f}x\")\n",
    "if avg_ratio > 2.0:\n",
    "    print(f\"   ‚úÖ Model correctly focuses on central tumor regions\")\n",
    "elif avg_ratio > 1.2:\n",
    "    print(f\"   ‚ö†Ô∏è Model shows moderate central focus\")\n",
    "else:\n",
    "    print(f\"   ‚ùå Model may be distracted by edge artifacts\")\n",
    "\n",
    "print(f\"\\n2Ô∏è‚É£ Prediction Quality:\")\n",
    "print(f\"   Correct predictions: {total_correct}/{total_samples} ({overall_accuracy:.1f}%)\")\n",
    "\n",
    "correct_confidences = [r['confidence'] for r in gradcam_results if r['true_label'] == r['pred_label']]\n",
    "incorrect_confidences = [r['confidence'] for r in gradcam_results if r['true_label'] != r['pred_label']]\n",
    "\n",
    "if correct_confidences:\n",
    "    print(f\"   Avg confidence (correct): {np.mean(correct_confidences):.1f}%\")\n",
    "if incorrect_confidences:\n",
    "    print(f\"   Avg confidence (incorrect): {np.mean(incorrect_confidences):.1f}%\")\n",
    "\n",
    "print(f\"\\n3Ô∏è‚É£ Clinical Implications:\")\n",
    "print(f\"   ‚úÖ Grad-CAM provides visual explanation of predictions\")\n",
    "print(f\"   ‚úÖ Helps radiologists verify model decisions\")\n",
    "print(f\"   ‚úÖ Can identify when model focuses on wrong regions\")\n",
    "print(f\"   ‚úÖ Increases trust in AI-assisted diagnosis\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"markdown\">\n",
    "## ‚úÖ Grad-CAM Analysis Complete - Summary\n",
    "\n",
    "### What We Accomplished:\n",
    "\n",
    "1. ‚úÖ **Implemented Grad-CAM** from scratch using TensorFlow\n",
    "2. ‚úÖ **Generated heatmaps** for 6 sample images (2 per class)\n",
    "3. ‚úÖ **Visualized attention patterns** with overlay images\n",
    "4. ‚úÖ **Analyzed focus regions** (center vs edges)\n",
    "5. ‚úÖ **Saved visualizations** for each tumor type\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "**üéØ Model Attention:**\n",
    "- Average center/edge ratio: {avg_ratio:.2f}x\n",
    "- Model {'focuses well on tumor regions' if avg_ratio > 2.0 else 'needs attention pattern improvement'}\n",
    "\n",
    "**üí° Clinical Value:**\n",
    "- Grad-CAM provides **visual explanation** of CNN decisions\n",
    "- Helps **validate** that model focuses on relevant anatomy\n",
    "- Enables **trust** in AI-assisted diagnosis\n",
    "- **Regulatory requirement** for medical AI deployment\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "- **Red/Yellow regions**: Model pays most attention here\n",
    "- **Should align with**: Tumor location in MRI\n",
    "- **If misaligned**: May indicate spurious correlations or artifacts\n",
    "\n",
    "### Medical AI Best Practices:\n",
    "\n",
    "‚úÖ **Always use Grad-CAM** for medical imaging models  \n",
    "‚úÖ **Validate with radiologists** that attention makes sense  \n",
    "‚úÖ **Check for artifacts** (image borders, text, etc.)  \n",
    "‚úÖ **Document findings** in model cards  \n",
    "\n",
    "---\n",
    "\n",
    "**Date:** October 22, 2025  \n",
    "**Status:** ‚úÖ Completed  \n",
    "**Samples Analyzed:** {total_samples}  \n",
    "**Avg Center/Edge Ratio:** {avg_ratio:.2f}x  \n",
    "\n",
    "---\n",
    "\n",
    "## üìö References\n",
    "\n",
    "1. Selvaraju et al., \"Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization\" (2017)\n",
    "2. FDA Guidance on AI/ML in Medical Devices\n",
    "3. European AI Act - Medical AI Requirements\n",
    "</VSCode.Cell>\n",
    "````"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
