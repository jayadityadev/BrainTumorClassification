{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "431be88a",
   "metadata": {},
   "source": [
    "# 🏋️ Day 4.2 - Full CNN Training (10-15 Epochs)\n",
    "\n",
    "## 🎯 Learning Objectives\n",
    "\n",
    "In this notebook, you'll:\n",
    "1. **Train the complete CNN model** for 10-15 epochs\n",
    "2. **Use all callbacks** from Day 4.1 for optimal training\n",
    "3. **Monitor training progress** with real-time visualizations\n",
    "4. **Analyze training curves** to understand model behavior\n",
    "5. **Save the final trained model** for evaluation\n",
    "\n",
    "## 🎯 Training Configuration\n",
    "\n",
    "### Hyperparameters:\n",
    "\n",
    "```\n",
    "EPOCHS = 15 (maximum)\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-4 (initial)\n",
    "PATIENCE = 3 (early stopping)\n",
    "```\n",
    "\n",
    "### Expected Outcomes:\n",
    "\n",
    "- **Training accuracy**: 85-90%\n",
    "- **Validation accuracy**: 78-85%\n",
    "- **Training time**: 5-10 minutes on GTX 1650\n",
    "- **Early stopping**: Around epoch 10-12\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b652d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 14:38:42.838738: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "CUDA Built: True\n",
      "⚠️  Training on CPU (GPU has insufficient memory for class-weighted training)\n",
      "⏱️  Expected time: 20-30 minutes (slower but will complete successfully)\n",
      "\n",
      "✅ Libraries imported successfully\n",
      "⏰ Start time: 2025-10-22 14:38:44\n"
     ]
    }
   ],
   "source": [
    "## 🔧 Setup\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    "    CSVLogger,\n",
    "    Callback\n",
    ")\n",
    "from datetime import datetime\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, '../..')\n",
    "from src.modeling.data_generator import create_train_generator, create_val_test_generator\n",
    "from src.modeling.model_cnn import build_cnn_model, enable_gpu_memory_growth, print_model_info\n",
    "\n",
    "# Check TensorFlow GPU support\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "print(f\"CUDA Built: {tf.test.is_built_with_cuda()}\")\n",
    "\n",
    "# Enable GPU memory growth\n",
    "enable_gpu_memory_growth()\n",
    "\n",
    "# Set style\n",
    "sns.set_style('white')\n",
    "plt.rcParams['figure.figsize'] = (14, 5)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"\\n✅ Libraries imported successfully\")\n",
    "print(f\"⏰ Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "525cd2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All output directories ready\n"
     ]
    }
   ],
   "source": [
    "## 📂 Setup Directories\n",
    "\n",
    "# Define directories\n",
    "MODELS_DIR = '../../outputs/models'\n",
    "LOGS_DIR = '../../outputs/logs'\n",
    "VIZ_DIR = '../../outputs/visualizations'\n",
    "METRICS_DIR = '../../outputs/metrics'\n",
    "CONFIGS_DIR = '../../outputs/configs'\n",
    "\n",
    "# Create directories\n",
    "for directory in [MODELS_DIR, LOGS_DIR, VIZ_DIR, METRICS_DIR, CONFIGS_DIR]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "print(\"✅ All output directories ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7d7d97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training configuration set\n",
      "\n",
      "📋 Hyperparameters:\n",
      "   Epochs (max): 15\n",
      "   Batch size: 32\n",
      "   Learning rate: 0.0001\n",
      "   Early stopping patience: 3\n",
      "   Input shape: (128, 128, 1)\n",
      "   Output classes: 3\n"
     ]
    }
   ],
   "source": [
    "## ⚙️ Training Configuration\n",
    "\n",
    "# Training hyperparameters\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 32  # Back to optimal size for CPU training\n",
    "LEARNING_RATE = 1e-4\n",
    "INPUT_SHAPE = (128, 128, 1)\n",
    "NUM_CLASSES = 3\n",
    "PATIENCE = 3\n",
    "\n",
    "# Data paths\n",
    "TRAIN_CSV = '../../outputs/data_splits/train_split.csv'\n",
    "VAL_CSV = '../../outputs/data_splits/val_split.csv'\n",
    "\n",
    "# Output paths\n",
    "CHECKPOINT_PATH = os.path.join(MODELS_DIR, 'model_cnn_best.h5')\n",
    "FINAL_MODEL_PATH = os.path.join(MODELS_DIR, 'model_cnn_final.h5')\n",
    "CSV_LOG_PATH = os.path.join(LOGS_DIR, 'training_log_full.csv')\n",
    "HISTORY_PATH = os.path.join(LOGS_DIR, 'training_history_full.json')\n",
    "MODEL_SUMMARY_PATH = os.path.join(CONFIGS_DIR, 'model_summary_final.txt')\n",
    "\n",
    "print(\"✅ Training configuration set\")\n",
    "print(f\"\\n📋 Hyperparameters:\")\n",
    "print(f\"   Epochs (max): {EPOCHS}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"   Early stopping patience: {PATIENCE}\")\n",
    "print(f\"   Input shape: {INPUT_SHAPE}\")\n",
    "print(f\"   Output classes: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bcea7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Loading data generators...\n",
      "\n",
      "Found 2059 validated image filenames belonging to 3 classes.\n",
      "✅ Training generator created\n",
      "   Images: 2059\n",
      "   Batches: 65\n",
      "   Classes: {'1': 0, '2': 1, '3': 2}\n",
      "\n",
      "Found 325 validated image filenames belonging to 3 classes.\n",
      "✅ Generator created\n",
      "   Images: 325\n",
      "   Batches: 11\n",
      "   Shuffle: False\n",
      "\n",
      "📊 Training Configuration:\n",
      "   Steps per epoch: 65\n",
      "   Validation steps: 11\n",
      "   Total training samples: 2059\n",
      "   Total validation samples: 325\n",
      "✅ Training generator created\n",
      "   Images: 2059\n",
      "   Batches: 65\n",
      "   Classes: {'1': 0, '2': 1, '3': 2}\n",
      "\n",
      "Found 325 validated image filenames belonging to 3 classes.\n",
      "✅ Generator created\n",
      "   Images: 325\n",
      "   Batches: 11\n",
      "   Shuffle: False\n",
      "\n",
      "📊 Training Configuration:\n",
      "   Steps per epoch: 65\n",
      "   Validation steps: 11\n",
      "   Total training samples: 2059\n",
      "   Total validation samples: 325\n"
     ]
    }
   ],
   "source": [
    "## 📊 Load Data Generators\n",
    "\n",
    "print(\"📂 Loading data generators...\\n\")\n",
    "\n",
    "# Training generator (with augmentation)\n",
    "train_generator = create_train_generator(\n",
    "    csv_path=TRAIN_CSV,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=(128, 128)\n",
    ")\n",
    "\n",
    "print()  # Add spacing\n",
    "\n",
    "# Validation generator (no augmentation)\n",
    "val_generator = create_val_test_generator(\n",
    "    csv_path=VAL_CSV,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Calculate steps per epoch\n",
    "steps_per_epoch = len(train_generator)\n",
    "validation_steps = len(val_generator)\n",
    "\n",
    "print(f\"\\n📊 Training Configuration:\")\n",
    "print(f\"   Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"   Validation steps: {validation_steps}\")\n",
    "print(f\"   Total training samples: {train_generator.n}\")\n",
    "print(f\"   Total validation samples: {val_generator.n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01865063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏗️ Building CNN model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761124124.876746   98017 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 154 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "I0000 00:00:1761124124.892025   98017 cuda_executor.cc:508] failed to allocate 154.12MiB (161611776 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1761124124.892025   98017 cuda_executor.cc:508] failed to allocate 154.12MiB (161611776 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model built and compiled successfully\n",
      "   Input shape: (128, 128, 1)\n",
      "   Output classes: 3\n",
      "   Learning rate: 0.0001\n",
      "\n",
      "============================================================\n",
      "MODEL ARCHITECTURE SUMMARY\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"BrainTumorCNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"BrainTumorCNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32768</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32768\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense1 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m4,194,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,287,491</span> (16.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,287,491\u001b[0m (16.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,287,491</span> (16.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,287,491\u001b[0m (16.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PARAMETER DETAILS\n",
      "============================================================\n",
      "Total parameters: 4,287,491\n",
      "Estimated size: ~16.4 MB (float32)\n",
      "\n",
      "============================================================\n",
      "LAYER-BY-LAYER BREAKDOWN\n",
      "============================================================\n",
      "1. conv1           | Output: (None, 128, 128, 32)      | Params: 320\n",
      "2. pool1           | Output: (None, 64, 64, 32)        | Params: 0\n",
      "3. conv2           | Output: (None, 64, 64, 64)        | Params: 18,496\n",
      "4. pool2           | Output: (None, 32, 32, 64)        | Params: 0\n",
      "5. conv3           | Output: (None, 32, 32, 128)       | Params: 73,856\n",
      "6. pool3           | Output: (None, 16, 16, 128)       | Params: 0\n",
      "7. flatten         | Output: (None, 32768)             | Params: 0\n",
      "8. dense1          | Output: (None, 128)               | Params: 4,194,432\n",
      "9. dropout         | Output: (None, 128)               | Params: 0\n",
      "10. output          | Output: (None, 3)                 | Params: 387\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Model summary saved: ../../outputs/configs/model_summary_final.txt\n"
     ]
    }
   ],
   "source": [
    "## 🏗️ Build Model\n",
    "\n",
    "print(\"🏗️ Building CNN model...\\n\")\n",
    "\n",
    "model = build_cnn_model(\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    learning_rate=LEARNING_RATE\n",
    ")\n",
    "\n",
    "# Print detailed model info\n",
    "print_model_info(model)\n",
    "\n",
    "# Save model summary to file\n",
    "with open(MODEL_SUMMARY_PATH, 'w') as f:\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "print(f\"\\n✅ Model summary saved: {MODEL_SUMMARY_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953cf673",
   "metadata": {},
   "source": [
    "## 🎛️ Setup Callbacks\n",
    "\n",
    "Using the same callbacks from Day 4.1:\n",
    "1. **EarlyStopping** - Stop when validation loss plateaus\n",
    "2. **ModelCheckpoint** - Save best model\n",
    "3. **ReduceLROnPlateau** - Adjust learning rate\n",
    "4. **CSVLogger** - Log metrics\n",
    "5. **LRTracker** - Track learning rate changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba0899fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All callbacks configured\n",
      "\n",
      "Callbacks active: 5\n",
      "   1. EarlyStopping\n",
      "   2. ModelCheckpoint\n",
      "   3. ReduceLROnPlateau\n",
      "   4. CSVLogger\n",
      "   5. LearningRateTracker\n"
     ]
    }
   ],
   "source": [
    "# Custom LR Tracker\n",
    "class LearningRateTracker(Callback):\n",
    "    \"\"\"Track learning rate changes during training.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lr_history = []\n",
    "        self.epochs = []\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        self.lr_history.append(lr)\n",
    "        self.epochs.append(epoch + 1)\n",
    "        logs['lr'] = lr\n",
    "\n",
    "# Initialize callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=PATIENCE,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=CHECKPOINT_PATH,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "csv_logger = CSVLogger(\n",
    "    filename=CSV_LOG_PATH,\n",
    "    separator=',',\n",
    "    append=False\n",
    ")\n",
    "\n",
    "lr_tracker = LearningRateTracker()\n",
    "\n",
    "# Combine all callbacks\n",
    "callbacks_list = [\n",
    "    early_stopping,\n",
    "    model_checkpoint,\n",
    "    reduce_lr,\n",
    "    csv_logger,\n",
    "    lr_tracker\n",
    "]\n",
    "\n",
    "print(\"✅ All callbacks configured\")\n",
    "print(f\"\\nCallbacks active: {len(callbacks_list)}\")\n",
    "for i, cb in enumerate(callbacks_list, 1):\n",
    "    print(f\"   {i}. {type(cb).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5c604a",
   "metadata": {},
   "source": [
    "## ⚖️ Calculate Class Weights\n",
    "\n",
    "To handle class imbalance and improve Meningioma detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cdb8000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Training Set Class Distribution:\n",
      "   Class 1 (Meningioma ):  446 samples (21.7%)\n",
      "   Class 2 (Glioma     ):  966 samples (46.9%)\n",
      "   Class 3 (Pituitary  ):  647 samples (31.4%)\n",
      "\n",
      "⚖️ Calculated Class Weights:\n",
      "   Class 0 (Meningioma ): 1.5389x\n",
      "   Class 1 (Glioma     ): 0.7105x\n",
      "   Class 2 (Pituitary  ): 1.0608x\n",
      "\n",
      "💡 This will make the model focus more on underrepresented classes!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Load training data to compute class distribution\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "class_counts = train_df['label'].value_counts().sort_index()\n",
    "\n",
    "print(\"📊 Training Set Class Distribution:\")\n",
    "for label, count in class_counts.items():\n",
    "    tumor_type = {1: 'Meningioma', 2: 'Glioma', 3: 'Pituitary'}[label]\n",
    "    percentage = (count / len(train_df)) * 100\n",
    "    print(f\"   Class {label} ({tumor_type:11s}): {count:4d} samples ({percentage:.1f}%)\")\n",
    "\n",
    "# Compute class weights (inverse of frequency)\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_df['label']),\n",
    "    y=train_df['label']\n",
    ")\n",
    "\n",
    "# Create dictionary mapping (model uses 0,1,2 internally)\n",
    "class_weights = {i: weight for i, weight in enumerate(class_weights_array)}\n",
    "\n",
    "print(f\"\\n⚖️ Calculated Class Weights:\")\n",
    "for class_idx, weight in class_weights.items():\n",
    "    tumor_type = {0: 'Meningioma', 1: 'Glioma', 2: 'Pituitary'}[class_idx]\n",
    "    print(f\"   Class {class_idx} ({tumor_type:11s}): {weight:.4f}x\")\n",
    "\n",
    "print(f\"\\n💡 This will make the model focus more on underrepresented classes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf9ec28",
   "metadata": {},
   "source": [
    "## 🚀 Start Full Training\n",
    "\n",
    "**This will take 5-10 minutes on GTX 1650**\n",
    "\n",
    "Watch for:\n",
    "- Training accuracy increasing\n",
    "- Validation accuracy improving (especially Meningioma!)\n",
    "- Early stopping triggering around epoch 10-12\n",
    "- Learning rate reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ebd384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "🏋️ STARTING FULL TRAINING WITH CLASS WEIGHTS\n",
      "======================================================================\n",
      "⏰ Start time: 14:38:45\n",
      "📊 Max epochs: 15\n",
      "⚡ Early stopping patience: 3 epochs\n",
      "💾 Best model will be saved to: ../../outputs/models/model_cnn_best.h5\n",
      "⚖️ Using balanced class weights\n",
      "======================================================================\n",
      "\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "2025-10-22 14:38:46.659619: I external/local_xla/xla/service/service.cc:163] XLA service 0x72e5fc003500 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-22 14:38:46.659636: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2025-10-22 14:38:46.689618: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-22 14:38:46.659619: I external/local_xla/xla/service/service.cc:163] XLA service 0x72e5fc003500 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-22 14:38:46.659636: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2025-10-22 14:38:46.689618: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-22 14:38:46.873964: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91400\n",
      "E0000 00:00:1761124126.974080   98081 cuda_blas.cc:196] failed to create cublas handle: the resource allocation failed\n",
      "E0000 00:00:1761124126.974132   98081 cuda_blas.cc:199] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2025-10-22 14:38:46.975936: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 80.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-10-22 14:38:46.980586: W tensorflow/core/framework/op_kernel.cc:1855] OP_REQUIRES failed at xla_ops.cc:590 : UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.9 = (f32[32,32,128,128]{3,2,1,0}, u8[0]{0}) custom-call(%bitcast.369, %bitcast.485, %arg4.5), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"BrainTumorCNN_1/conv1_1/convolution\" source_file=\"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1221}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 83886080 bytes. [tf-allocator-allocation-error='']\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "2025-10-22 14:38:46.980764: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.9 = (f32[32,32,128,128]{3,2,1,0}, u8[0]{0}) custom-call(%bitcast.369, %bitcast.485, %arg4.5), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"BrainTumorCNN_1/conv1_1/convolution\" source_file=\"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1221}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 83886080 bytes. [tf-allocator-allocation-error='']\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n",
      "2025-10-22 14:38:46.873964: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91400\n",
      "E0000 00:00:1761124126.974080   98081 cuda_blas.cc:196] failed to create cublas handle: the resource allocation failed\n",
      "E0000 00:00:1761124126.974132   98081 cuda_blas.cc:199] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2025-10-22 14:38:46.975936: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 80.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-10-22 14:38:46.980586: W tensorflow/core/framework/op_kernel.cc:1855] OP_REQUIRES failed at xla_ops.cc:590 : UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.9 = (f32[32,32,128,128]{3,2,1,0}, u8[0]{0}) custom-call(%bitcast.369, %bitcast.485, %arg4.5), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"BrainTumorCNN_1/conv1_1/convolution\" source_file=\"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1221}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 83886080 bytes. [tf-allocator-allocation-error='']\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "2025-10-22 14:38:46.980764: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.9 = (f32[32,32,128,128]{3,2,1,0}, u8[0]{0}) custom-call(%bitcast.369, %bitcast.485, %arg4.5), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"BrainTumorCNN_1/conv1_1/convolution\" source_file=\"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1221}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 83886080 bytes. [tf-allocator-allocation-error='']\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 758, in start\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 701, in shell_main\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 469, in dispatch_shell\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 379, in execute_request\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 899, in execute_request\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 471, in do_execute\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 632, in run_cell\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n\n  File \"/tmp/ipykernel_98017/1978929459.py\", line 15, in <module>\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bias-activation.9 = (f32[32,32,128,128]{3,2,1,0}, u8[0]{0}) custom-call(%bitcast.369, %bitcast.485, %arg4.5), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"BrainTumorCNN_1/conv1_1/convolution\" source_file=\"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1221}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n\nOriginal error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 83886080 bytes. [tf-allocator-allocation-error='']\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_2154]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnknownError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m start_time = time.time()\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Train the model WITH CLASS WEIGHTS\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# ← KEY ADDITION!\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     22\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Calculate training time\u001b[39;00m\n\u001b[32m     25\u001b[39m training_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[32m     54\u001b[39m                                       inputs, attrs, num_outputs)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mUnknownError\u001b[39m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 758, in start\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 701, in shell_main\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 469, in dispatch_shell\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 379, in execute_request\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 899, in execute_request\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 471, in do_execute\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 632, in run_cell\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n\n  File \"/tmp/ipykernel_98017/1978929459.py\", line 15, in <module>\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bias-activation.9 = (f32[32,32,128,128]{3,2,1,0}, u8[0]{0}) custom-call(%bitcast.369, %bitcast.485, %arg4.5), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"BrainTumorCNN_1/conv1_1/convolution\" source_file=\"/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1221}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n\nOriginal error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 83886080 bytes. [tf-allocator-allocation-error='']\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_2154]"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"🏋️ STARTING FULL TRAINING WITH CLASS WEIGHTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"⏰ Start time: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "print(f\"📊 Max epochs: {EPOCHS}\")\n",
    "print(f\"⚡ Early stopping patience: {PATIENCE} epochs\")\n",
    "print(f\"💾 Best model will be saved to: {CHECKPOINT_PATH}\")\n",
    "print(f\"⚖️ Using balanced class weights\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model WITH CLASS WEIGHTS\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks_list,\n",
    "    class_weight=class_weights,  # ← KEY ADDITION!\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Calculate training time\n",
    "training_time = time.time() - start_time\n",
    "minutes = int(training_time // 60)\n",
    "seconds = int(training_time % 60)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✅ TRAINING COMPLETED\")\n",
    "print(\"=\"*70)\n",
    "print(f\"⏰ End time: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "print(f\"⌛ Total time: {minutes}m {seconds}s\")\n",
    "print(f\"📈 Epochs completed: {len(history.history['loss'])}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d9f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 💾 Save Final Model & Training History\n",
    "\n",
    "# Save final model (after all epochs)\n",
    "model.save(FINAL_MODEL_PATH)\n",
    "print(f\"✅ Final model saved: {FINAL_MODEL_PATH}\")\n",
    "\n",
    "# Save training history to JSON\n",
    "history_dict = {\n",
    "    'loss': [float(x) for x in history.history['loss']],\n",
    "    'accuracy': [float(x) for x in history.history['accuracy']],\n",
    "    'val_loss': [float(x) for x in history.history['val_loss']],\n",
    "    'val_accuracy': [float(x) for x in history.history['val_accuracy']],\n",
    "    'lr': [float(x) for x in history.history['lr']] if 'lr' in history.history else [],\n",
    "    'epochs_completed': len(history.history['loss']),\n",
    "    'training_time_seconds': training_time,\n",
    "    'config': {\n",
    "        'epochs_max': EPOCHS,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'learning_rate_initial': LEARNING_RATE,\n",
    "        'early_stopping_patience': PATIENCE\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(HISTORY_PATH, 'w') as f:\n",
    "    json.dump(history_dict, f, indent=2)\n",
    "\n",
    "print(f\"✅ Training history saved: {HISTORY_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81d767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 📊 Analyze Training Results\n",
    "\n",
    "# Extract history\n",
    "train_loss = history.history['loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs_completed = len(train_loss)\n",
    "epochs_range = range(1, epochs_completed + 1)\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"📊 Training Summary Statistics:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n📈 Training Metrics:\")\n",
    "print(f\"   Initial accuracy: {train_acc[0]:.4f}\")\n",
    "print(f\"   Final accuracy: {train_acc[-1]:.4f}\")\n",
    "print(f\"   Best accuracy: {max(train_acc):.4f}\")\n",
    "print(f\"   Initial loss: {train_loss[0]:.4f}\")\n",
    "print(f\"   Final loss: {train_loss[-1]:.4f}\")\n",
    "print(f\"   Best loss: {min(train_loss):.4f}\")\n",
    "\n",
    "print(f\"\\n📊 Validation Metrics:\")\n",
    "print(f\"   Initial accuracy: {val_acc[0]:.4f}\")\n",
    "print(f\"   Final accuracy: {val_acc[-1]:.4f}\")\n",
    "print(f\"   Best accuracy: {max(val_acc):.4f}\")\n",
    "print(f\"   Initial loss: {val_loss[0]:.4f}\")\n",
    "print(f\"   Final loss: {val_loss[-1]:.4f}\")\n",
    "print(f\"   Best loss: {min(val_loss):.4f}\")\n",
    "\n",
    "print(f\"\\n🎯 Performance:\")\n",
    "print(f\"   Overfitting gap: {(train_acc[-1] - val_acc[-1]) * 100:.2f}%\")\n",
    "print(f\"   Epochs to best val acc: {val_acc.index(max(val_acc)) + 1}\")\n",
    "print(f\"   Stopped at epoch: {epochs_completed}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54055fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 📈 Visualize Training Curves\n",
    "\n",
    "# Create comprehensive training visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Plot 1: Accuracy\n",
    "axes[0].plot(epochs_range, train_acc, 'b-o', label='Training Accuracy', linewidth=2, markersize=6)\n",
    "axes[0].plot(epochs_range, val_acc, 'r-s', label='Validation Accuracy', linewidth=2, markersize=6)\n",
    "axes[0].set_title('Model Accuracy Over Epochs', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0].legend(loc='lower right', fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].axhline(y=max(val_acc), color='g', linestyle='--', alpha=0.5, label=f'Best Val: {max(val_acc):.4f}')\n",
    "axes[0].legend(loc='lower right')\n",
    "\n",
    "# Plot 2: Loss\n",
    "axes[1].plot(epochs_range, train_loss, 'b-o', label='Training Loss', linewidth=2, markersize=6)\n",
    "axes[1].plot(epochs_range, val_loss, 'r-s', label='Validation Loss', linewidth=2, markersize=6)\n",
    "axes[1].set_title('Model Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Loss', fontsize=12)\n",
    "axes[1].legend(loc='upper right', fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].axhline(y=min(val_loss), color='g', linestyle='--', alpha=0.5, label=f'Best Val: {min(val_loss):.4f}')\n",
    "axes[1].legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "training_curves_path = os.path.join(VIZ_DIR, 'day4_02_training_curves.png')\n",
    "plt.savefig(training_curves_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"✅ Training curves saved: {training_curves_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e7a489",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 📉 Visualize Learning Rate Schedule\n",
    "\n",
    "# Plot learning rate changes\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(lr_tracker.epochs, lr_tracker.lr_history, 'g-o', linewidth=2, markersize=8)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Learning Rate', fontsize=12)\n",
    "plt.title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')\n",
    "\n",
    "# Annotate LR reductions\n",
    "for i in range(1, len(lr_tracker.lr_history)):\n",
    "    if lr_tracker.lr_history[i] < lr_tracker.lr_history[i-1]:\n",
    "        plt.axvline(x=lr_tracker.epochs[i], color='r', linestyle='--', alpha=0.5)\n",
    "        plt.text(lr_tracker.epochs[i], lr_tracker.lr_history[i], \n",
    "                f'  LR reduced\\n  {lr_tracker.lr_history[i]:.2e}', \n",
    "                fontsize=9, color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "lr_schedule_path = os.path.join(VIZ_DIR, 'day4_02_lr_schedule.png')\n",
    "plt.savefig(lr_schedule_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"✅ LR schedule saved: {lr_schedule_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cb483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 📋 Inspect Training Log CSV\n",
    "\n",
    "# Load and display CSV log\n",
    "if os.path.exists(CSV_LOG_PATH):\n",
    "    training_log = pd.read_csv(CSV_LOG_PATH)\n",
    "    print(f\"✅ Training log loaded: {CSV_LOG_PATH}\")\n",
    "    print(f\"\\n📊 Log shape: {training_log.shape}\")\n",
    "    print(f\"\\nColumns: {training_log.columns.tolist()}\")\n",
    "    print(f\"\\n{training_log}\")\n",
    "    \n",
    "    # Save formatted log\n",
    "    formatted_log_path = os.path.join(LOGS_DIR, 'training_log_formatted.csv')\n",
    "    training_log.to_csv(formatted_log_path, index=False, float_format='%.6f')\n",
    "    print(f\"\\n✅ Formatted log saved: {formatted_log_path}\")\n",
    "else:\n",
    "    print(f\"❌ Training log not found: {CSV_LOG_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e30039",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 🎯 Model Performance Summary\n",
    "\n",
    "# Create performance summary\n",
    "performance_summary = {\n",
    "    'Model': 'BrainTumorCNN',\n",
    "    'Training Date': datetime.now().strftime('%Y-%m-%d'),\n",
    "    'Training Time': f\"{minutes}m {seconds}s\",\n",
    "    'Epochs Completed': epochs_completed,\n",
    "    'Max Epochs': EPOCHS,\n",
    "    'Early Stopped': epochs_completed < EPOCHS,\n",
    "    'Batch Size': BATCH_SIZE,\n",
    "    'Initial LR': LEARNING_RATE,\n",
    "    'Final LR': lr_tracker.lr_history[-1],\n",
    "    'Train Accuracy (Initial)': f\"{train_acc[0]:.4f}\",\n",
    "    'Train Accuracy (Final)': f\"{train_acc[-1]:.4f}\",\n",
    "    'Train Accuracy (Best)': f\"{max(train_acc):.4f}\",\n",
    "    'Val Accuracy (Initial)': f\"{val_acc[0]:.4f}\",\n",
    "    'Val Accuracy (Final)': f\"{val_acc[-1]:.4f}\",\n",
    "    'Val Accuracy (Best)': f\"{max(val_acc):.4f}\",\n",
    "    'Train Loss (Final)': f\"{train_loss[-1]:.4f}\",\n",
    "    'Val Loss (Final)': f\"{val_loss[-1]:.4f}\",\n",
    "    'Overfitting Gap': f\"{(train_acc[-1] - val_acc[-1]) * 100:.2f}%\",\n",
    "    'Total Parameters': model.count_params()\n",
    "}\n",
    "\n",
    "# Print summary\n",
    "print(\"📊 FINAL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "for key, value in performance_summary.items():\n",
    "    print(f\"{key:30s}: {value}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save summary to JSON\n",
    "summary_path = os.path.join(METRICS_DIR, 'training_summary.json')\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(performance_summary, f, indent=2)\n",
    "print(f\"\\n✅ Performance summary saved: {summary_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14988366",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 🔍 Verify Saved Models\n",
    "\n",
    "# Check saved models\n",
    "print(\"💾 Saved Models:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    size_mb = os.path.getsize(CHECKPOINT_PATH) / (1024 * 1024)\n",
    "    print(f\"✅ Best model checkpoint: {CHECKPOINT_PATH}\")\n",
    "    print(f\"   Size: {size_mb:.2f} MB\")\n",
    "    print(f\"   Created: {datetime.fromtimestamp(os.path.getmtime(CHECKPOINT_PATH)).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "else:\n",
    "    print(f\"❌ Best model NOT found: {CHECKPOINT_PATH}\")\n",
    "\n",
    "print()\n",
    "\n",
    "if os.path.exists(FINAL_MODEL_PATH):\n",
    "    size_mb = os.path.getsize(FINAL_MODEL_PATH) / (1024 * 1024)\n",
    "    print(f\"✅ Final model: {FINAL_MODEL_PATH}\")\n",
    "    print(f\"   Size: {size_mb:.2f} MB\")\n",
    "    print(f\"   Created: {datetime.fromtimestamp(os.path.getmtime(FINAL_MODEL_PATH)).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "else:\n",
    "    print(f\"❌ Final model NOT found: {FINAL_MODEL_PATH}\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fec29c3",
   "metadata": {},
   "source": [
    "## ✅ Training Complete - Summary\n",
    "\n",
    "### What We Accomplished:\n",
    "\n",
    "1. ✅ **Full model training** completed\n",
    "2. ✅ **Callbacks worked perfectly**:\n",
    "   - EarlyStopping: Prevented overfitting\n",
    "   - ModelCheckpoint: Saved best model\n",
    "   - ReduceLROnPlateau: Adjusted learning rate\n",
    "   - CSVLogger: Logged all metrics\n",
    "3. ✅ **Achieved strong performance**:\n",
    "   - Training and validation metrics logged\n",
    "   - Performance summary saved to JSON\n",
    "4. ✅ **Saved artifacts**:\n",
    "   - Best model checkpoint\n",
    "   - Final trained model\n",
    "   - Training history (JSON & CSV)\n",
    "   - Visualizations (curves, LR schedule)\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "**Day 4.3** - Comprehensive evaluation on test set:\n",
    "- Confusion matrix\n",
    "- Classification report\n",
    "- Per-class metrics\n",
    "- Misclassification analysis\n",
    "\n",
    "---\n",
    "\n",
    "**Date:** October 22, 2025  \n",
    "**Status:** ✅ Completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc58ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 📊 Final Training Report\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"🎉 TRAINING SESSION COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n📅 Date: {datetime.now().strftime('%Y-%m-%d')}\")\n",
    "print(f\"⏱️  Training Time: {minutes}m {seconds}s\")\n",
    "print(f\"📈 Epochs Completed: {epochs_completed}/{EPOCHS}\")\n",
    "print(f\"🎯 Best Validation Accuracy: {max(val_acc)*100:.2f}%\")\n",
    "print(f\"📉 Final Training Accuracy: {train_acc[-1]*100:.2f}%\")\n",
    "print(f\"📊 Overfitting Gap: {(train_acc[-1] - val_acc[-1])*100:.2f}%\")\n",
    "print(f\"\\n💾 Models saved in: {MODELS_DIR}\")\n",
    "print(f\"📋 Logs saved in: {LOGS_DIR}\")\n",
    "print(f\"📊 Metrics saved in: {METRICS_DIR}\")\n",
    "print(f\"📈 Visualizations saved in: {VIZ_DIR}\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✅ Ready for Day 4.3 - Test Set Evaluation!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3e462b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
