{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6af309ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 14:29:41.701125: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.20.0\n",
      "GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "✅ Memory growth enabled for 1 GPU(s)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, Callback\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, '../..')\n",
    "from src.modeling.data_generator import create_train_generator, create_val_test_generator\n",
    "from src.modeling.model_cnn import build_cnn_model, enable_gpu_memory_growth\n",
    "\n",
    "# Setup\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(f\"GPU: {tf.config.list_physical_devices('GPU')}\")\n",
    "enable_gpu_memory_growth()\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bc32a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Directories ready\n"
     ]
    }
   ],
   "source": [
    "# Output directories\n",
    "MODELS_DIR = '../../outputs/models'\n",
    "LOGS_DIR = '../../outputs/logs'\n",
    "VIZ_DIR = '../../outputs/visualizations'\n",
    "\n",
    "for directory in [MODELS_DIR, LOGS_DIR, VIZ_DIR]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "print(\"✅ Directories ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b725d527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configured 5 callbacks:\n",
      "   1. EarlyStopping\n",
      "   2. ModelCheckpoint\n",
      "   3. ReduceLROnPlateau\n",
      "   4. CSVLogger\n",
      "   5. LRTracker\n"
     ]
    }
   ],
   "source": [
    "# 🛠️ Configure Callbacks\n",
    "# 1. Early Stopping - stop when val_loss stops improving\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 2. Model Checkpoint - save best model\n",
    "checkpoint_path = os.path.join(MODELS_DIR, 'model_cnn_best.h5')\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 3. Reduce LR - halve learning rate when plateau\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 4. CSV Logger - log metrics\n",
    "csv_log_path = os.path.join(LOGS_DIR, 'training_log.csv')\n",
    "csv_logger = CSVLogger(csv_log_path)\n",
    "\n",
    "# 5. Custom LR Tracker\n",
    "class LRTracker(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lrs = []\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        self.lrs.append(lr)\n",
    "        logs['lr'] = lr\n",
    "\n",
    "lr_tracker = LRTracker()\n",
    "\n",
    "# Combine all callbacks\n",
    "callbacks_list = [early_stopping, model_checkpoint, reduce_lr, csv_logger, lr_tracker]\n",
    "\n",
    "print(f\"✅ Configured {len(callbacks_list)} callbacks:\")\n",
    "for i, cb in enumerate(callbacks_list, 1):\n",
    "    print(f\"   {i}. {type(cb).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1dff209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing callbacks with 2-epoch training...\n",
      "\n",
      "Found 2059 validated image filenames belonging to 3 classes.\n",
      "✅ Training generator created\n",
      "   Images: 2059\n",
      "   Batches: 65\n",
      "   Classes: {'1': 0, '2': 1, '3': 2}\n",
      "Found 325 validated image filenames belonging to 3 classes.\n",
      "✅ Training generator created\n",
      "   Images: 2059\n",
      "   Batches: 65\n",
      "   Classes: {'1': 0, '2': 1, '3': 2}\n",
      "Found 325 validated image filenames belonging to 3 classes.\n",
      "✅ Generator created\n",
      "   Images: 325\n",
      "   Batches: 11\n",
      "   Shuffle: False\n",
      "✅ Generator created\n",
      "   Images: 325\n",
      "   Batches: 11\n",
      "   Shuffle: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761123584.054244   95809 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 755 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model built and compiled successfully\n",
      "   Input shape: (128, 128, 1)\n",
      "   Output classes: 3\n",
      "   Learning rate: 0.0001\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/ai-ml/BrainTumorProject/.venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "2025-10-22 14:29:45.696407: I external/local_xla/xla/service/service.cc:163] XLA service 0x7814c00067e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-22 14:29:45.696427: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2025-10-22 14:29:45.726681: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-22 14:29:45.696407: I external/local_xla/xla/service/service.cc:163] XLA service 0x7814c00067e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-22 14:29:45.696427: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2025-10-22 14:29:45.726681: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-22 14:29:45.916228: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91400\n",
      "2025-10-22 14:29:45.916228: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91400\n",
      "2025-10-22 14:29:46.237735: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[32,32,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,128,128]{3,2,1,0}, f32[32,1,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "2025-10-22 14:29:46.256314: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 532.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-10-22 14:29:46.260107: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[32,64,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,64,64]{3,2,1,0}, f32[64,32,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "2025-10-22 14:29:46.237735: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[32,32,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,128,128]{3,2,1,0}, f32[32,1,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "2025-10-22 14:29:46.256314: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 532.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-10-22 14:29:46.260107: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[32,64,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,64,64]{3,2,1,0}, f32[64,32,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "2025-10-22 14:29:46.445842: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 406.07MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-10-22 14:29:46.476247: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[32,128,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,32,32]{3,2,1,0}, f32[128,64,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "2025-10-22 14:29:46.497953: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:382] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2025-10-22 14:29:46.445842: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 406.07MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-10-22 14:29:46.476247: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[32,128,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,32,32]{3,2,1,0}, f32[128,64,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "2025-10-22 14:29:46.497953: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:382] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2025-10-22 14:29:47.111582: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 612.12MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-10-22 14:29:47.111582: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 612.12MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 5/65\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.3770 - loss: 1.0809"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1761123589.008304   97029 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/65\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5108 - loss: 0.9998"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 14:29:50.288550: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[11,32,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[11,1,128,128]{3,2,1,0}, f32[32,1,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "2025-10-22 14:29:50.331815: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[11,64,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[11,32,64,64]{3,2,1,0}, f32[64,32,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "2025-10-22 14:29:50.468470: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[11,128,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[11,64,32,32]{3,2,1,0}, f32[128,64,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5541 - loss: 0.9528"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 14:29:53.611410: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[32,32,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,128,128]{3,2,1,0}, f32[32,1,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "2025-10-22 14:29:53.626113: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 532.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-10-22 14:29:53.628979: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[32,64,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,64,64]{3,2,1,0}, f32[64,32,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "2025-10-22 14:29:53.855276: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[32,128,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,32,32]{3,2,1,0}, f32[128,64,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "2025-10-22 14:29:53.855276: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[32,128,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,32,32]{3,2,1,0}, f32[128,64,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "2025-10-22 14:29:54.387347: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[5,32,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[5,1,128,128]{3,2,1,0}, f32[32,1,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "2025-10-22 14:29:54.485455: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[5,64,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[5,32,64,64]{3,2,1,0}, f32[64,32,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "2025-10-22 14:29:54.572432: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[5,128,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[5,64,32,32]{3,2,1,0}, f32[128,64,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "2025-10-22 14:29:54.387347: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[5,32,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[5,1,128,128]{3,2,1,0}, f32[32,1,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "2025-10-22 14:29:54.485455: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[5,64,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[5,32,64,64]{3,2,1,0}, f32[64,32,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "2025-10-22 14:29:54.572432: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[5,128,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[5,64,32,32]{3,2,1,0}, f32[128,64,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from None to 0.70769, saving model to ../../outputs/models/model_cnn_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - accuracy: 0.6037 - loss: 0.8928 - val_accuracy: 0.7077 - val_loss: 0.7075 - learning_rate: 1.0000e-04 - lr: 1.0000e-04\n",
      "Epoch 2/2\n",
      "Epoch 2/2\n",
      "\u001b[1m64/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6275 - loss: 0.8082\n",
      "Epoch 2: val_accuracy improved from 0.70769 to 0.74769, saving model to ../../outputs/models/model_cnn_best.h5\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.70769 to 0.74769, saving model to ../../outputs/models/model_cnn_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.6406 - loss: 0.8060 - val_accuracy: 0.7477 - val_loss: 0.6474 - learning_rate: 1.0000e-04 - lr: 1.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\n",
      "✅ Test complete!\n",
      "\n",
      "✅ Test complete!\n"
     ]
    }
   ],
   "source": [
    "# 🧪 Test Callbacks with Short Training\n",
    "print(\"🧪 Testing callbacks with 2-epoch training...\\n\")\n",
    "\n",
    "# Load data\n",
    "train_gen = create_train_generator('../../outputs/data_splits/train_split.csv', batch_size=32)\n",
    "val_gen = create_val_test_generator('../../outputs/data_splits/val_split.csv', batch_size=32)\n",
    "\n",
    "# Build model\n",
    "model = build_cnn_model(input_shape=(128, 128, 1), num_classes=3, learning_rate=1e-4)\n",
    "\n",
    "# Train with callbacks\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=2,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Test complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e48451a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved: ../../outputs/models/model_cnn_best.h5 (49.1 MB)\n",
      "\n",
      "✅ Training log: ../../outputs/logs/training_log.csv\n",
      "   Columns: ['epoch', 'accuracy', 'learning_rate', 'loss', 'val_accuracy', 'val_loss']\n",
      "\n",
      "   epoch  accuracy  learning_rate      loss  val_accuracy  val_loss\n",
      "0      0  0.603691         0.0001  0.892764      0.707692  0.707465\n",
      "1      1  0.640602         0.0001  0.806024      0.747692  0.647421\n",
      "\n",
      "✅ LR plot saved\n",
      "\n",
      "✅ LR plot saved\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Check checkpoint\n",
    "if os.path.exists(checkpoint_path):\n",
    "    size_mb = os.path.getsize(checkpoint_path) / (1024 * 1024)\n",
    "    print(f\"✅ Model saved: {checkpoint_path} ({size_mb:.1f} MB)\")\n",
    "else:\n",
    "    print(\"❌ Model not saved\")\n",
    "\n",
    "# Check logs\n",
    "if os.path.exists(csv_log_path):\n",
    "    log_df = pd.read_csv(csv_log_path)\n",
    "    print(f\"\\n✅ Training log: {csv_log_path}\")\n",
    "    print(f\"   Columns: {list(log_df.columns)}\")\n",
    "    print(f\"\\n{log_df}\")\n",
    "else:\n",
    "    print(\"\\n❌ Log not created\")\n",
    "\n",
    "# Plot LR\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(range(1, len(lr_tracker.lrs)+1), lr_tracker.lrs, 'b-o', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Learning Rate Schedule')\n",
    "plt.yscale('log')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(os.path.join(VIZ_DIR, 'day4_01_lr_schedule_test.png'), dpi=150, bbox_inches='tight')\n",
    "print(\"\\n✅ LR plot saved\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76396aa9",
   "metadata": {},
   "source": [
    "## ✅ Summary\n",
    "\n",
    "**Callbacks configured:**\n",
    "1. EarlyStopping - stops at overfitting\n",
    "2. ModelCheckpoint - saves best model\n",
    "3. ReduceLROnPlateau - adjusts learning rate\n",
    "4. CSVLogger - logs metrics\n",
    "5. LRTracker - tracks LR changes\n",
    "\n",
    "**Ready for full training in Day 4.2!**\n",
    "\n",
    "---\n",
    "**Status:** ✅ Complete  \n",
    "**Next:** `day4_02_full_training.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
