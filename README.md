# üß† Brain Tumor Classification

**High-accuracy deep learning system for classifying brain tumors from MRI images.**

## üéØ Project Overview

This project achieves **99.23% accuracy** in classifying brain tumors into four categories:
- **Glioma** (malignant, most aggressive)
- **Meningioma** (usually benign)
- **Pituitary** (affects hormones)
- **No Tumor** (healthy brain)

### Key Features
- ‚úÖ **99.23% accuracy** (validated on test set)
- ‚úÖ **Real-time inference** (~50ms per image)
- ‚úÖ **Grad-CAM visualization** (explainable AI)
- ‚úÖ **Web interface** (Flask app)
- ‚úÖ **Production-ready** code

## üìä Dataset

The project supports two dataset options:

1. **CE-MRI Dataset**: 3,064 brain MRI scans (.mat format)
   - Source: [Figshare - Brain Tumor Dataset](https://figshare.com/articles/dataset/brain_tumor_dataset/1512427)
   - 233 unique patients
   - Contrast-enhanced MRI (512√ó512)
   
2. **Kaggle Dataset**: ~7,000 brain MRI images
   - Source: [Kaggle - Brain Tumor MRI Dataset](https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset)
   - Pre-organized by class
   - Ready to use

### üì• Download Datasets

**Option 1: Fully Automated Download** (recommended):
```bash
python scripts/download_datasets.py
```
The script automatically handles:
- CE-MRI: Downloads nested ZIP, extracts 4 sub-ZIPs, organizes 3064 .mat files
- Kaggle: Uses Kaggle CLI (requires API key setup)
- Progress bars and automatic cleanup

**Option 2: Manual Download** (if automated fails):

**CE-MRI Dataset**:
1. Visit: https://figshare.com/ndownloader/articles/1512427/versions/5
2. Download starts automatically as `1512427.zip` (~900MB)
3. Extract ‚Üí You'll get a folder with 4 sub-ZIPs:
   - `brainTumorDataPublic_1-766.zip`
   - `brainTumorDataPublic_767-1532.zip`
   - `brainTumorDataPublic_1533-2298.zip`
   - `brainTumorDataPublic_2299-3064.zip`
4. Extract each sub-ZIP and copy all .mat files to `datasets/ce-mri/`

**Kaggle Dataset**:
1. Install Kaggle CLI: `pip install kaggle`
2. Get API credentials from https://www.kaggle.com/settings (Create New API Token)
3. Place `kaggle.json` in `~/.kaggle/`
4. Run: `kaggle datasets download -d masoudnickparvar/brain-tumor-mri-dataset`
5. Extract to `datasets/kaggle/`
   
> üìñ **See [docs/REPRODUCTION_GUIDE.md](docs/REPRODUCTION_GUIDE.md) for complete setup instructions**


## üöÄ Quick Start

### 1. Setup Environment

```bash
# Clone repository
git clone https://github.com/jayadityadev/BrainTumorClassification.git
cd BrainTumorProject

# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# Install dependencies
# Choose ONE based on your hardware:

# Option A: GPU (NVIDIA - 10-12x faster!)
pip install -r requirements-gpu.txt

# Option B: CPU (works everywhere, but slower)
pip install -r requirements-cpu.txt

# Create directories
python scripts/setup_directories.py
```

> **üí° GPU vs CPU:** Training on GPU takes ~15-20 minutes vs 2-3 hours on CPU.  
> **Requirements for GPU:** NVIDIA GPU (GTX 1060+) + drivers 525.x or newer.  
> **Check GPU:** Run `nvidia-smi` to verify your GPU is available.

### 2. Download & Prepare Data

```bash
# Download datasets (fully automated!)
python scripts/download_datasets.py

# The script automatically:
# - Downloads CE-MRI dataset (nested ZIP structure)
# - Extracts 3064 .mat files from 4 sub-ZIPs
# - Downloads Kaggle dataset (requires API key)
# - Organizes everything in datasets/ directory

# Manual download (if automated fails):
# - CE-MRI: https://figshare.com/ndownloader/articles/1512427/versions/5
#   Download 1512427.zip ‚Üí Extract ‚Üí Extract 4 sub-ZIPs ‚Üí Copy .mat files to datasets/ce-mri/
# - Kaggle: https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset
#   Download ‚Üí Extract to: datasets/kaggle/

# Preprocess (if using .mat files)
python src/preprocessing/convert_mat_to_png.py
python src/preprocessing/enhance.py

# Combine the downloaded datasets
python src/data/combine_datasets.py
```

### 3. Train Model

```bash
# Fast fine-tuning (recommended, ~15-20 min on GPU)
python src/models/fast_finetune_kaggle.py

# Full training (combined dataset, ~30-40 min)
python src/models/train_combined_dataset.py
```

### 4. Validate & Run

```bash
# Validate system (10 comprehensive tests)
python scripts/validate_system.py

# Launch web app
python app.py
# Open browser: http://localhost:5000
```

## üìÅ Project Structure

```
BrainTumorProject/
‚îú‚îÄ‚îÄ app.py                    # Web application
‚îú‚îÄ‚îÄ requirements.txt          # Python dependencies
‚îú‚îÄ‚îÄ README.md                 # This file
‚îÇ
‚îú‚îÄ‚îÄ scripts/                  # Utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ setup_directories.py  # Directory setup
‚îÇ   ‚îú‚îÄ‚îÄ download_datasets.py  # Dataset downloader
‚îÇ   ‚îú‚îÄ‚îÄ validate_system.py    # System validation
‚îÇ   ‚îî‚îÄ‚îÄ evaluate_kaggle.py    # Model evaluation
‚îÇ
‚îú‚îÄ‚îÄ src/                      # Source code
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/        # Data preprocessing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ convert_mat_to_png.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ enhance.py
‚îÇ   ‚îú‚îÄ‚îÄ models/               # Training scripts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_combined_dataset.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ fast_finetune_kaggle.py
‚îÇ   ‚îú‚îÄ‚îÄ inference/            # Prediction & visualization
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predict.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gradcam.py
‚îÇ   ‚îî‚îÄ‚îÄ data/                 # Data utilities
‚îÇ
‚îú‚îÄ‚îÄ docs/                     # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ README.md             # Documentation index
‚îÇ   ‚îú‚îÄ‚îÄ REPRODUCTION_GUIDE.md # Complete reproduction guide
‚îÇ   ‚îú‚îÄ‚îÄ ARCHITECTURE.md       # System architecture
‚îÇ   ‚îú‚îÄ‚îÄ SETUP.md              # Installation guide
‚îÇ   ‚îú‚îÄ‚îÄ CLEANUP_SUMMARY.md    # Minimization summary
‚îÇ   ‚îî‚îÄ‚îÄ DISTRIBUTION_CHECKLIST.md  # Sharing checklist
‚îÇ
‚îú‚îÄ‚îÄ templates/                # Web UI
‚îÇ
‚îî‚îÄ‚îÄ [Generated directories]   # Created by setup_directories.py
    ‚îú‚îÄ‚îÄ datasets/             # Downloaded datasets
    ‚îÇ   ‚îú‚îÄ‚îÄ ce-mri/          # Original .mat files
    ‚îÇ   ‚îî‚îÄ‚îÄ kaggle/          # Kaggle images
    ‚îú‚îÄ‚îÄ data/                 # Processed data
    ‚îú‚îÄ‚îÄ models/current/       # Trained models
    ‚îú‚îÄ‚îÄ outputs/              # Predictions, logs, reports
    ‚îî‚îÄ‚îÄ config/               # Configuration files
```


## üî¨ Technical Details

### Model Architecture
- **Base Model**: DenseNet121 (pretrained on ImageNet)
- **Input**: 224√ó224√ó3 RGB images
- **Output**: 4 classes (softmax)
- **Parameters**: ~7M trainable

### Preprocessing Pipeline
1. **Non-Local Means Denoising** - Removes noise while preserving edges
2. **CLAHE** (Contrast Limited Adaptive Histogram Equalization) - Enhances contrast
3. **Center Crop & Resize** - Standardizes image size

> ‚ö†Ô∏è **Critical**: The preprocessing step is essential for 99%+ accuracy. Without it, accuracy drops to ~85-90%.

### Performance Metrics
- **Accuracy**: 99.23%
- **Precision**: 99.24%
- **Recall**: 99.23%
- **F1-Score**: 99.23%
- **Inference Time**: ~50ms per image (GPU)

### Hardware Requirements
- **Minimum**: 16GB RAM, CPU
- **Recommended**: 32GB RAM, NVIDIA GPU (8GB+ VRAM)
- **Training Time**: 
  - GPU (RTX 3080): ~15-20 minutes
  - GPU (RTX 4090): ~8-12 minutes
  - CPU: ~2-4 hours (not recommended)

## üìñ Documentation

- üìò **[docs/REPRODUCTION_GUIDE.md](docs/REPRODUCTION_GUIDE.md)** - Complete step-by-step reproduction
- üèóÔ∏è **[docs/ARCHITECTURE.md](docs/ARCHITECTURE.md)** - System architecture & design
- ‚öôÔ∏è **[docs/SETUP.md](docs/SETUP.md)** - Installation & configuration
- üßπ **[docs/CLEANUP_SUMMARY.md](docs/CLEANUP_SUMMARY.md)** - Minimization summary
- ‚úÖ **[docs/DISTRIBUTION_CHECKLIST.md](docs/DISTRIBUTION_CHECKLIST.md)** - Sharing checklist

## üõ†Ô∏è Tech Stack

- **Deep Learning**: TensorFlow 2.13+, Keras
- **Image Processing**: OpenCV, Pillow
- **Data Science**: NumPy, Pandas, scikit-learn
- **Visualization**: Matplotlib, Seaborn
- **Web Framework**: Flask
- **MATLAB Files**: h5py, scipy

## üêõ Troubleshooting

### GPU Not Detected
```bash
# Check GPU availability
python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"

# If no GPU, install CUDA/cuDNN or use CPU (slower)
```

### Low Accuracy (<90%)
- **Cause**: Missing image enhancement
- **Solution**: Run `python src/preprocessing/enhance.py` before training

### Out of Memory
- **Solution**: Reduce batch size in training script (32 ‚Üí 16 or 8)

### More Help
See [REPRODUCTION_GUIDE.md](REPRODUCTION_GUIDE.md) for detailed troubleshooting.

## üìä Results

### Confusion Matrix
```
                 Predicted
               G    M    N    P
Actual    G   99%  0%   1%   0%
          M   0%  100%  0%   0%
          N   0%   0%  100%  0%
          P   1%   0%   0%  99%
```

### Per-Class Performance
- **Glioma**: 99.1% accuracy
- **Meningioma**: 99.5% accuracy  
- **No Tumor**: 100.0% accuracy
- **Pituitary**: 98.8% accuracy

## ü§ù Contributing

This project is open for contributions! Areas of interest:
- Additional datasets
- Model optimization
- New visualization techniques
- Deployment improvements

## üìù License

Educational/Research project. See LICENSE file.

## üë§ Author

**Jayaditya Dev**
- GitHub: [@jayadityadev](https://github.com/jayadityadev)
- Email: jayadityadev261204@gmail.com

---

**‚≠ê If you find this project helpful, please star the repository!**

*Last Updated: October 26, 2025 | Version 2.0*

## üöÄ Upcoming Work

### Day 4: Full Training & Evaluation
- Full CNN training (10-15 epochs)
- Comprehensive evaluation on test set
- Confusion matrix & classification reports
- Model saving & export
- Ablation study: original vs enhanced images

## üõ†Ô∏è Tech Stack

- **Python**: 3.11.14
- **Libraries**: 
  - TensorFlow 2.x with CUDA (deep learning)
  - OpenCV 4.12.0 (image processing)
  - NumPy, SciPy (numerical computing)
  - Matplotlib, Seaborn (visualization)
  - scikit-learn (ML utilities)
  - h5py (MAT file handling)
  - tqdm (progress tracking)

## üíª Hardware Optimization

- **CPU**: AMD Ryzen 5 5600H (12 cores @ 4.28 GHz)
- **GPU**: NVIDIA GeForce GTX 1650 Mobile
- **Optimization**: Multi-core parallel processing (75% CPU utilization)

## üìñ Documentation

Detailed completion logs available:
- [Day 1 Completion Log](docs/DAY1_COMPLETION_LOG.md) - Data extraction
- [Day 2 Completion Log](docs/DAY2_COMPLETION_LOG.md) - Image enhancement
- [Day 3 Completion Log](docs/DAY3_COMPLETION_LOG.md) - CNN model setup
- [Day 3 Notebooks Guide](docs/DAY3_NOTEBOOKS_GUIDE.md) - Notebook walkthrough

## üöÄ Quick Start

> **üìò New to this project?** Check the [Execution Guide](EXECUTION_GUIDE.md) for:
> - Fast Path vs Learning Path
> - What notebooks are mandatory
> - Our actual execution history
> - When to re-run things

### 1. Environment Setup

```bash
# Clone the repository
git clone https://github.com/jayadityadev/BrainTumorClassification.git
cd BrainTumorProject

# Create and activate virtual environment
python3 -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install tensorflow opencv-python numpy scipy h5py pandas matplotlib seaborn scikit-learn tqdm jupyter ipykernel

# Register Jupyter kernel
python -m ipykernel install --user --name=braintumor-venv --display-name="Python (BrainTumor)"
```

### 2. Running the Pipeline

#### **Day 1: Data Extraction**
```bash
# Extract images from .mat files
python src/preprocessing/convert_mat_to_png.py

# Or run notebooks in order:
jupyter notebook notebooks/day1/day1_dataset_explore.ipynb
```

**Output**: 3,064 PNG images + masks in `outputs/ce_mri_images/` and `outputs/ce_mri_masks/`

#### **Day 2: Image Enhancement**
```bash
# Run enhancement pipeline
python src/preprocessing/module1_enhance.py

# Or use the notebook:
jupyter notebook notebooks/day2/day2_enhancement.ipynb
```

**Output**: Enhanced images in `outputs/ce_mri_enhanced/` with 54.1% avg contrast improvement

#### **Day 3: CNN Model Setup**
```bash
# Run all Day 3 notebooks sequentially:
cd notebooks/day3

# 1. Data splitting (patient-wise, no leakage)
jupyter notebook day3_01_data_splitting.ipynb

# 2. Data augmentation setup
jupyter notebook day3_02_data_augmentation.ipynb

# 3. CNN architecture design
jupyter notebook day3_03_cnn_architecture.ipynb

# 4. Training pipeline validation (3 epochs)
jupyter notebook day3_04_training_test.ipynb
```

**Output**: 
- Train/val/test splits in `outputs/data_splits/`
- Model configs in `outputs/configs/`
- Training history & visualizations

### 3. Running Tests

```bash
# Test Day 1 completion
python tests/day1/test_day1.py

# Test Day 2 completion
python tests/day2/test_day2.py

# Test Day 3 completion (comprehensive)
python tests/day3/test_day3_completion.py
```

**Expected Results**: All tests should pass with ‚úì green checkmarks

### 4. Module Usage Examples

#### Using the Data Generator
```python
from src.modeling.data_generator import create_train_generator, create_val_test_generator

# Create training generator with augmentation
train_gen = create_train_generator(
    csv_path='outputs/data_splits/train_split.csv',
    batch_size=32,
    target_size=(128, 128)
)

# Create validation generator (no augmentation)
val_gen = create_val_test_generator(
    csv_path='outputs/data_splits/val_split.csv',
    batch_size=32,
    target_size=(128, 128)
)
```

#### Using the CNN Model
```python
from src.modeling.model_cnn import build_cnn_model, print_model_info

# Build model
model = build_cnn_model(input_shape=(128, 128, 1), num_classes=3)

# Print detailed info
print_model_info(model)

# Compile and train
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit(train_gen, validation_data=val_gen, epochs=10)
```

### 5. Using Custom Modules in Notebooks

```python
# Add src to Python path
import sys
sys.path.insert(0, '../..')

# Import modules
from src.modeling.data_generator import create_train_generator
from src.modeling.model_cnn import build_cnn_model
from src.utils.visualize_enhancement import plot_comparison
```

## üìä Expected Results

### Day 1
- ‚úÖ 3,064 images extracted successfully (100% success rate)
- ‚úÖ Metadata CSV with patient IDs and labels
- ‚úÖ Visual validation plots

### Day 2
- ‚úÖ 54.1% average contrast improvement
- ‚úÖ Processing speed: ~210 images/sec (9 workers)
- ‚úÖ Before/after comparison visualizations

### Day 3
- ‚úÖ Patient-wise splits: 2,059 train / 325 val / 680 test
- ‚úÖ Zero patient leakage confirmed
- ‚úÖ CNN model: ~4.29M parameters
- ‚úÖ 3-epoch test: 76.31% validation accuracy
- ‚úÖ Training time: ~13 seconds (GPU-accelerated)

### Day 4 (Upcoming)
- üîÑ Full training: 10-15 epochs
- üîÑ Expected accuracy: 80-85%
- üîÑ Test set evaluation with confusion matrix
- üîÑ Model export & ablation study

## ÔøΩüî¨ Research Context

This project focuses on automated brain tumor classification to assist medical diagnosis. The three tumor types have distinct characteristics:
- **Meningioma**: Most common, usually benign
- **Glioma**: Most aggressive, requires urgent treatment
- **Pituitary**: Affects hormone regulation

## üêõ Troubleshooting

### Kernel Connection Issues
```bash
# Kill hung kernels
pkill -9 -f "jupyter|ipykernel"

# Reinstall kernel
.venv/bin/python -m ipykernel install --user --name=braintumor-venv
```

### Import Errors in Notebooks
```python
# Always add this at the top of notebooks
import sys
sys.path.insert(0, '../..')  # Adjust based on notebook location
```

### GPU Not Detected
```python
import tensorflow as tf
print("GPU Available:", tf.config.list_physical_devices('GPU'))

# Enable memory growth
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    tf.config.experimental.set_memory_growth(gpus[0], True)
```

### Label Type Errors with ImageDataGenerator
```python
# Ensure labels are strings
df['label'] = df['label'].astype(str)
```

## üìö Documentation

Detailed completion logs available in `docs/`:
- [Execution Guide](EXECUTION_GUIDE.md) - **START HERE**: Fast vs Learning paths
- [Quick Reference](QUICK_REFERENCE.md) - Common commands & file locations
- [Day 1 Completion Log](docs/DAY1_COMPLETION_LOG.md) - Data extraction
- [Day 2 Completion Log](docs/DAY2_COMPLETION_LOG.md) - Image enhancement
- [Day 3 Completion Log](docs/DAY3_COMPLETION_LOG.md) - CNN model setup
- [Day 3 Notebooks Guide](docs/DAY3_NOTEBOOKS_GUIDE.md) - Notebook walkthrough

## üìù License

This is a research/educational project.

## üë§ Author

**Jayaditya Dev**
- Email: jayadityadev261204@gmail.com
- GitHub: [@jayadityadev](https://github.com/jayadityadev)

---

*Last Updated: October 21, 2025*

````
